begin;

-- =============================================================
-- Batch: Seed from manual inferred question list
-- Parsed: 348, kept: 339, skipped: 9
-- Topic distribution: {"debugging-and-monitoring":6,"integration-patterns":54,"crud-fls-sharing":8,"asynchronous-apex":35,"soql-and-dml-optimization":12,"platform-events-and-cdc":15,"lwc-fundamentals":24,"lwc-component-communication":14,"lwc-rendering-lifecycle":12,"lwc-data-and-performance":10,"lwc-wire-service":16,"apex-fundamentals":53,"slack-integrations":5,"lwc-security-and-cross-domain":1,"lwc-flow-integration":6,"payment-integrations":8,"docusign-integrations":4,"oauth-and-named-credentials":10,"governor-limits":9,"flow-automation-patterns":6,"apex-triggers":20,"apex-testing":2,"stakeholder-and-behavioral-scenarios":8,"mixed-dml-operations":1}
-- =============================================================

-- PART 1: Categories - none (using existing 'salesforce')
-- PART 2: Subcategories - none (using existing canonical subcategories)

-- PART 3: Topics (new topics only)
insert into public.topics (slug, name, short_description, overview_markdown, status, published_at, sort_order, subcategory_id)
select
  seed.slug, seed.name, seed.short_description, seed.overview_markdown,
  'published'::public.content_status, timezone('utc', now()), seed.sort_order, s.id
from (
  values
    (
      'governor-limits',
      'Governor Limits',
      'CPU, heap, SOQL, DML, and callout limits with scalable mitigation strategies',
      $ov$## Overview

Governor Limits focuses on cpu, heap, soql, dml, and callout limits with scalable mitigation strategies.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      160
    ),
    (
      'soql-and-dml-optimization',
      'SOQL and DML Optimization',
      'Selective query design, pagination, indexing, and partial-success DML handling',
      $ov$## Overview

SOQL and DML Optimization focuses on selective query design, pagination, indexing, and partial-success dml handling.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      170
    )
) as seed(slug, name, short_description, overview_markdown, sort_order)
join public.subcategories s on s.slug = 'apex-programming'
on conflict (slug) do update
set
  name = excluded.name,
  short_description = excluded.short_description,
  overview_markdown = excluded.overview_markdown,
  status = excluded.status,
  published_at = coalesce(public.topics.published_at, excluded.published_at),
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

insert into public.topics (slug, name, short_description, overview_markdown, status, published_at, sort_order, subcategory_id)
select
  seed.slug, seed.name, seed.short_description, seed.overview_markdown,
  'published'::public.content_status, timezone('utc', now()), seed.sort_order, s.id
from (
  values
    (
      'flow-automation-patterns',
      'Flow Automation Patterns',
      'Flow design, trigger-flow coordination, and automation guardrails for stable org behavior',
      $ov$## Overview

Flow Automation Patterns focuses on flow design, trigger-flow coordination, and automation guardrails for stable org behavior.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      10
    )
) as seed(slug, name, short_description, overview_markdown, sort_order)
join public.subcategories s on s.slug = 'automation-and-config'
on conflict (slug) do update
set
  name = excluded.name,
  short_description = excluded.short_description,
  overview_markdown = excluded.overview_markdown,
  status = excluded.status,
  published_at = coalesce(public.topics.published_at, excluded.published_at),
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

insert into public.topics (slug, name, short_description, overview_markdown, status, published_at, sort_order, subcategory_id)
select
  seed.slug, seed.name, seed.short_description, seed.overview_markdown,
  'published'::public.content_status, timezone('utc', now()), seed.sort_order, s.id
from (
  values
    (
      'debugging-and-monitoring',
      'Debugging and Monitoring',
      'Production incident triage, log-driven diagnosis, and instrumentation for root cause analysis',
      $ov$## Overview

Debugging and Monitoring focuses on production incident triage, log-driven diagnosis, and instrumentation for root cause analysis.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      10
    ),
    (
      'stakeholder-and-behavioral-scenarios',
      'Stakeholder and Behavioral Scenarios',
      'Interview scenarios on communication, ownership, and delivery execution across teams',
      $ov$## Overview

Stakeholder and Behavioral Scenarios focuses on interview scenarios on communication, ownership, and delivery execution across teams.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      20
    )
) as seed(slug, name, short_description, overview_markdown, sort_order)
join public.subcategories s on s.slug = 'development-practices'
on conflict (slug) do update
set
  name = excluded.name,
  short_description = excluded.short_description,
  overview_markdown = excluded.overview_markdown,
  status = excluded.status,
  published_at = coalesce(public.topics.published_at, excluded.published_at),
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

insert into public.topics (slug, name, short_description, overview_markdown, status, published_at, sort_order, subcategory_id)
select
  seed.slug, seed.name, seed.short_description, seed.overview_markdown,
  'published'::public.content_status, timezone('utc', now()), seed.sort_order, s.id
from (
  values
    (
      'integration-patterns',
      'Integration Resilience Patterns',
      'Reliable API integrations with retries, idempotency, throttling, and failure recovery',
      $ov$## Overview

Integration Resilience Patterns focuses on reliable api integrations with retries, idempotency, throttling, and failure recovery.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      10
    ),
    (
      'platform-events-and-cdc',
      'Platform Events and CDC',
      'Event-driven integration using Platform Events, CDC, replay handling, and ordering strategies',
      $ov$## Overview

Platform Events and CDC focuses on event-driven integration using platform events, cdc, replay handling, and ordering strategies.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      20
    ),
    (
      'oauth-and-named-credentials',
      'OAuth and Named Credentials',
      'Secure authentication, token refresh handling, and external identity patterns in Salesforce',
      $ov$## Overview

OAuth and Named Credentials focuses on secure authentication, token refresh handling, and external identity patterns in salesforce.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      30
    ),
    (
      'slack-integrations',
      'Slack Integrations',
      'Bidirectional Slack workflows, modal interactions, and reliable message delivery from Salesforce',
      $ov$## Overview

Slack Integrations focuses on bidirectional slack workflows, modal interactions, and reliable message delivery from salesforce.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      40
    ),
    (
      'payment-integrations',
      'Payment Integrations',
      'Payment API design with exactly-once semantics, reconciliation, and timeout-safe processing',
      $ov$## Overview

Payment Integrations focuses on payment api design with exactly-once semantics, reconciliation, and timeout-safe processing.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      50
    ),
    (
      'docusign-integrations',
      'DocuSign Integrations',
      'Envelope orchestration, callback processing, and secure signature workflow integration',
      $ov$## Overview

DocuSign Integrations focuses on envelope orchestration, callback processing, and secure signature workflow integration.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      60
    )
) as seed(slug, name, short_description, overview_markdown, sort_order)
join public.subcategories s on s.slug = 'integration'
on conflict (slug) do update
set
  name = excluded.name,
  short_description = excluded.short_description,
  overview_markdown = excluded.overview_markdown,
  status = excluded.status,
  published_at = coalesce(public.topics.published_at, excluded.published_at),
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

insert into public.topics (slug, name, short_description, overview_markdown, status, published_at, sort_order, subcategory_id)
select
  seed.slug, seed.name, seed.short_description, seed.overview_markdown,
  'published'::public.content_status, timezone('utc', now()), seed.sort_order, s.id
from (
  values
    (
      'lwc-fundamentals',
      'LWC Fundamentals',
      'Core LWC concepts including decorators, templates, lifecycle, and component boundaries',
      $ov$## Overview

LWC Fundamentals focuses on core lwc concepts including decorators, templates, lifecycle, and component boundaries.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      40
    ),
    (
      'lwc-data-and-performance',
      'LWC Data and Performance',
      'High-volume rendering, API call coordination, caching, and responsive UI data pipelines',
      $ov$## Overview

LWC Data and Performance focuses on high-volume rendering, api call coordination, caching, and responsive ui data pipelines.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      50
    ),
    (
      'lwc-flow-integration',
      'LWC and Flow Integration',
      'Launching flows from LWC, handling status events, and keeping UI state synchronized',
      $ov$## Overview

LWC and Flow Integration focuses on launching flows from lwc, handling status events, and keeping ui state synchronized.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      60
    ),
    (
      'lwc-security-and-cross-domain',
      'LWC Security and Cross-Domain Messaging',
      'postMessage safety, sensitive data boundaries, and secure communication with external contexts',
      $ov$## Overview

LWC Security and Cross-Domain Messaging focuses on postmessage safety, sensitive data boundaries, and secure communication with external contexts.

## Key Concepts

- Understand transaction boundaries and how data moves between layers.
- Keep implementations bulk-safe, idempotent, and observable.
- Design for retries, partial failures, and long-term maintainability.

## Interview Focus

Interviewers use this topic to assess structured reasoning, platform-specific tradeoffs, and production readiness in Salesforce solutions.$ov$,
      70
    )
) as seed(slug, name, short_description, overview_markdown, sort_order)
join public.subcategories s on s.slug = 'lwc-development'
on conflict (slug) do update
set
  name = excluded.name,
  short_description = excluded.short_description,
  overview_markdown = excluded.overview_markdown,
  status = excluded.status,
  published_at = coalesce(public.topics.published_at, excluded.published_at),
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

-- PART 4: Questions
-- Questions chunk 1
insert into public.questions (slug, title, summary, question_type, seniority_level, status, published_at)
select
  seed.slug, seed.title, seed.summary, seed.question_type, seed.seniority_level,
  'published'::public.content_status, timezone('utc', now())
from (
  values
    ('you-have-a-recursive-trigger-on-a-custom-object-and-under-ce', 'You have a recursive trigger on a custom object, and under certain data loads, you''re seeing Maximum trigger depth exceeded errors only intermittently. You''ve already added recursion guards. How do you identify the hidden recursive path and debug it without altering the data model or disabling triggers?', 'Assesses your ability to reason through debugging and monitoring constraints in Salesforce.', 'scenario', 'mid'),
    ('a-custom-apex-rest-service-starts-throwing-regex-too-complic', 'A custom Apex REST service starts throwing Regex too complicated errors after a recent deployment, but no regex patterns were modified. How would you trace the root cause and debug potential hidden regex compilation issues in large Apex classes?', 'Assesses your ability to reason through debugging and monitoring constraints in Salesforce.', 'scenario', 'mid'),
    ('an-apex-class-uses-type-forname-and-type-newinstance-for-dyn', 'An Apex class uses Type.forName() and Type.newInstance() for dynamic instantiation. In production, the instantiation randomly fails with System.TypeException: Invalid type. The class exists and compiles. How would you debug this behavior?', 'Assesses your ability to reason through debugging and monitoring constraints in Salesforce.', 'scenario', 'senior'),
    ('you-re-debugging-a-too-many-queueable-jobs-added-to-the-queu', 'You''re debugging a Too many queueable jobs added to the queue error, but your logic only adds 1 chain per job. There are multiple integrations running in parallel, and the issue doesn''t reproduce in sandbox. How would you debug and guard against hidden job fan-outs?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('you-have-a-method-that-runs-perfectly-in-an-anonymous-window', 'You have a method that runs perfectly in an anonymous window but fails in a Lightning component with a System.SObjectException: Field is not writeable error on a custom field. The field is accessible via FLS. What hidden cause might be triggering this, and how do you debug it?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'scenario', 'mid'),
    ('how-do-you-ensure-atomicity-and-rollback-capabilities-when-d', 'How do you ensure atomicity and rollback capabilities when DML operations on related objects occur asynchronously across batch execute boundaries?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('how-would-you-implement-a-transactional-idempotent-batch-job', 'How would you implement a transactional, idempotent batch job that integrates with multiple external systems via chained callouts, ensuring rollback, deduplication, and exactly once delivery semantics across batch retries and platform restarts?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'architect'),
    ('how-do-you-guarantee-data-consistency-and-transactional-inte', 'How do you guarantee data consistency and transactional integrity when performing cross object DML operations that span multiple batch execute transactions, especially under partial failures and asynchronous reprocessing scenarios?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'scenario', 'architect'),
    ('how-would-you-propose-to-process-hierarchical-interdependent', 'How would you propose to process hierarchical, interdependent records (e.g., Account Opportunity CustomObject__c) across shared data volumes exceeding heap and query limits, and how would you avoid lock contention and race conditions?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'scenario', 'architect'),
    ('how-can-you-maintain-referential-integrity-and-avoid-orphane', 'How can you maintain referential integrity and avoid orphaned records during partial batch failures and retries in complex object hierarchies?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-you-tackle-a-governor-limit-resilient-chain-of-queue', 'How can you tackle a governor limit resilient chain of Queueables that conditionally branches logic and persists context across transactions?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'senior'),
    ('how-do-you-build-a-platform-native-retry-mesh-that-tracks-jo', 'How do you build a platform native retry mesh that tracks job lineage, avoids duplicates, and obeys platform governor rules?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'senior'),
    ('how-would-you-coordinate-a-multi-pattern-async-convergence-w', 'How would you coordinate a multi pattern async convergence without external schedulers or platform events out of order issues?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'architect'),
    ('how-do-you-control-job-explosion-enforce-execution-priority', 'How do you control job explosion, enforce execution priority, and apply load throttling across async layers where each Queueable spawns child jobs dynamically based on runtime data?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'architect'),
    ('how-do-you-enforce-distributed-rollback-coordination-across', 'How do you enforce distributed rollback coordination across isolated async contexts without exceeding platform limits or duplicating work?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'architect'),
    ('since-apex-can-t-directly-receive-webhooks-how-can-you-route', 'Since Apex can''t directly receive webhooks, how can you route external webhook data to an LWC in real time?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-an-lwc-concurrently-handle-both-platform-events-and', 'How can an LWC concurrently handle both Platform Events and PushTopic events with separate logic for each?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'standard', 'senior'),
    ('how-would-you-design-an-lwc-that-processes-cdc-events-for-mi', 'How would you design an LWC that processes CDC events for millions of records without hitting limits?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'senior'),
    ('how-can-you-add-retry-logic-in-an-lwc-to-handle-temporary-ap', 'How can you add retry logic in an LWC to handle temporary API failures without sending too many requests?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'senior'),
    ('how-do-you-handle-out-of-order-cdc-events-in-lwc-when-multip', 'How do you handle out-of-order CDC events in LWC when multiple field updates on a record arrive nearly simultaneously?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'standard', 'mid'),
    ('parent-uses-import-c-childcomp-for-lazy-load-child-uses-wire', 'Parent uses import(\"c/childComp\") for lazy load. Child uses @wire(getRecord) with @api recordId. Sometimes data doesn''t load. Why?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'code_review', 'mid'),
    ('lwc-uses-buildcustomevent-with-bubbling-composition-but-pare', 'LWC uses buildCustomEvent() with bubbling/composition, but parent in another package can''t catch it. What''s the blocker?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'code_review', 'mid'),
    ('lwc-injects-third-party-widget-in-renderedcallback-via-direc', 'LWC injects third-party widget in renderedCallback() via direct shadow DOM edits. Other components break. What''s the anti-pattern?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'code_review', 'mid'),
    ('lwc-uses-lightning-record-edit-form-with-dynamic-recordid-an', 'LWC uses lightning-record-edit-form with dynamic recordId and objectApiName. Fast switching causes fields to fail. What''s wrong?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'code_review', 'mid'),
    ('in-a-nested-lwc-dashboard-inline-edits-in-one-chart-don-t-re', 'In a nested LWC dashboard, inline edits in one chart don''t reflect in others without a full reload. How would you redesign cross component data sync without relying on event flooding?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'senior'),
    ('you-built-a-reusable-datatable-with-wire-and-onsave-but-team', 'You built a reusable datatable with @wire and onSave, but teams report inconsistent inline edit behavior. What design changes ensure clean separation of data, edit lifecycle, and refresh logic for true reusability?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'scenario', 'senior'),
    ('your-component-uses-track-for-data-mutations-after-edit-but', 'Your component uses @track for data mutations after edit, but updates don''t reflect. What''s the risk of directly mutating tracked arrays in LWC?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('multiple-lwcs-show-the-same-data-source-after-update-in-one', 'Multiple LWCs show the same data source. After update in one, others don''t sync. How do you implement shared reactive state across components?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('you-re-combining-getrecord-with-imperative-updates-after-sav', 'You''re combining getRecord with imperative updates. After saving, changes don''t show unless you reload. What''s the reactive safe fix?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'code_review', 'mid'),
    ('when-multiple-lwcs-subscribe-to-the-same-lightning-message-c', 'When multiple LWCs subscribe to the same Lightning Message Channel, how do you prevent message causing performance degradation?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('what-are-the-implications-of-caching-wire-service-data-in-lw', 'What are the implications of caching wire service data in LWCs for highly dynamic datasets?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'junior'),
    ('how-to-manage-component-lifecycle-issues-when-an-lwc-is-dest', 'How to manage component lifecycle issues when an LWC is destroyed before async Apex call completes?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'mid'),
    ('how-to-implement-multi-language-support-for-dynamic-field-la', 'How to implement multi-language support for dynamic field labels in LWCs?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-to-handle-partial-page-refreshes-in-lwcs-embedded-in-aur', 'How to handle partial page refreshes in LWCs embedded in Aura components?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('you-re-syncing-contacts-across-3-external-systems-via-platfo', 'You''re syncing Contacts across 3 external systems via Platform Events. How will you ensure event deduplication and reliable delivery without breaching limits?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'mid'),
    ('contact-events-are-arriving-before-related-account-data-how', 'Contact events are arriving before related Account data. How do you handle this ordering issue with PushTopics?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('your-cdc-setup-handles-500k-events-daily-some-events-are-del', 'Your CDC setup handles 500K+ events daily. Some events are delayed or dropped. How do you scale and ensure reliable processing?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'architect'),
    ('intermittent-timeout-errors-are-impacting-api-reliability-ho', 'Intermittent timeout errors are impacting API reliability. How do you build fault tolerance into the design?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'senior'),
    ('given-graphql-is-in-pilot-how-would-you-design-a-performant', 'Given GraphQL is in pilot, how would you design a performant data fetching layer in Salesforce using GraphQL and handle governor limits?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'senior'),
    ('you-need-to-sync-5-million-product-records-between-orgs-do-y', 'You need to sync 5 million product records between orgs. Do you use CDC, Bulk API, or both and why?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'architect'),
    ('what-are-the-key-lifecycle-events-in-a-websocket-connection', 'What are the key lifecycle events in a WebSocket connection, and how can they be handled?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'junior'),
    ('can-you-explain-how-lazy-loading-images-or-data-can-affect-a', 'Can you explain how lazy loading images or data can affect accessibility?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'junior'),
    ('what-are-the-security-implications-of-exposing-sensitive-dat', 'What are the security implications of exposing sensitive data in headers?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'junior'),
    ('how-do-you-manage-state-effectively-across-components-in-a-l', 'How do you manage state effectively across components in a Lightning Web Component (LWC) app?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-integrate-custom-validation-messages-that-are-bot', 'How do you integrate custom validation messages that are both accessible and localized ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-s-the-best-way-to-secure-the-inbound-slack-interaction', 'What''s the best way to secure the inbound Slack interaction before processing it in Salesforce?', 'Assesses your ability to reason through slack integrations constraints in Salesforce.', 'standard', 'junior'),
    ('can-you-open-a-slack-modal-from-a-button-click-in-slack-itse', 'Can you open a Slack modal from a button click in Slack itself, and sync the input back to Salesforce?', 'Assesses your ability to reason through slack integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-ensure-message-delivery-to-slack-is-reliable-e', 'How would you ensure message delivery to Slack is reliable even if the Salesforce transaction rolls back?', 'Assesses your ability to reason through slack integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-handle-different-slack-modals-dynamically-base', 'How would you handle different Slack modals dynamically based on the Salesforce object type triggering the event?', 'Assesses your ability to reason through slack integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-do-you-prevent-duplicate-slack-messages-if-the-same-plat', 'How do you prevent duplicate Slack messages if the same platform event is replayed?', 'Assesses your ability to reason through slack integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('an-lwc-fetches-data-from-3-async-sources-apex-a-platform-eve', 'An LWC fetches data from 3 async sources: Apex, a Platform Event, and a third party API . How will you manage consistent state in the UI ?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'mid'),
    ('you-re-building-a-secure-lwc-page-that-uses-apex-to-fetch-se', 'You''re building a secure LWC page that uses Apex to fetch sensitive data. The client is worried about exposure. How can you resolve this ?', 'Assesses your ability to reason through lwc security and cross-domain messaging constraints in Salesforce.', 'scenario', 'mid'),
    ('your-lwc-makes-a-call-to-apex-but-the-response-takes-3-secon', 'Your LWC makes a call to Apex, but the response takes 3 seconds and blocks UI interaction. How can you fix this ?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('you-need-to-load-different-versions-of-the-same-third-party', 'You need to load different versions of the same third-party library for two components on the same page. How to do it ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('you-re-combining-lightning-data-service-and-custom-apex-call', 'You''re combining Lightning Data Service and custom Apex calls in the same LWC. How to maintain consistency in such case ?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('after-launching-a-flow-from-lwc-how-do-you-handle-the-onstat', 'After launching a Flow from LWC, how do you handle the onstatuschange event to show a success toast?', 'Assesses your ability to reason through lwc and flow integration constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-refresh-lwc-data-after-the-embedded-flow-updates', 'How do you refresh LWC data after the embedded Flow updates a record?', 'Assesses your ability to reason through lwc and flow integration constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-you-start-an-embedded-flow-in-lwc-only-when-a-custom', 'How can you start an embedded Flow in LWC only when a custom button is clicked and not on render?', 'Assesses your ability to reason through lwc and flow integration constraints in Salesforce.', 'standard', 'mid'),
    ('you-need-to-trigger-a-flow-from-lwc-only-after-multiple-asyn', 'You need to trigger a Flow from LWC only after multiple async Apex calls complete. How would you do this ?', 'Assesses your ability to reason through lwc and flow integration constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-handle-governor-limits-and-dml-constraints-if', 'How would you handle governor limits and DML constraints if a Flow (launched from LWC) deals with bulk updates?', 'Assesses your ability to reason through lwc and flow integration constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-initiate-a-stripe-payment-from-an-lwc-componen', 'How would you initiate a Stripe payment from an LWC component?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-do-you-handle-stripe-webhooks-in-a-salesforce-integrated', 'How do you handle Stripe webhooks in a Salesforce integrated payment flow?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('can-you-walk-through-a-use-case-where-a-user-purchases-a-pro', 'Can you walk through a use case where a user purchases a product using Stripe via LWC?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-track-payment-success-or-failure-in-salesforce', 'How would you track payment success or failure in Salesforce after Stripe redirects the user?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('what-security-measures-should-be-taken-when-handling-stripe', 'What security measures should be taken when handling Stripe payment info in LWC?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'standard', 'mid'),
    ('what-role-do-wire-adapters-play-in-the-provider-pattern-arch', 'What role do @wire adapters play in the Provider Pattern architecture in LWC?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'architect'),
    ('how-can-you-decouple-business-logic-from-ui-in-a-factory-pro', 'How can you decouple business logic from UI in a Factory + Provider Pattern setup?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('in-a-factory-pattern-how-do-you-maintain-state-consistency-a', 'In a Factory Pattern, how do you maintain state consistency across dynamically instantiated components ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-are-the-limitations-of-using-wire-in-a-factory-generate', 'What are the limitations of using @wire in a factory generated component tree ?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'junior'),
    ('describe-a-mechanism-to-dynamically-bind-different-wire-adap', 'Describe a mechanism to dynamically bind different wire adapters at runtime in an LWC ?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-you-leverage-browser-storage-like-sessionstorage-or', 'How can you leverage browser storage (like sessionStorage or IndexedDB) to implement persistent caching in LWC?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-wire-caching-differ-from-imperative-call-caching', 'How does @wire caching differ from imperative call caching?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('can-you-use-sessionstorage-or-localstorage-for-lwc-caching', 'Can you use sessionStorage or localStorage for LWC caching?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-would-you-implement-a-hybrid-cache-combining-in-memory-s', 'How would you implement a hybrid cache combining in-memory, sessionStorage, and LDS in LWC?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-can-platform-events-or-cdc-help-manage-stale-cache-in-lw', 'How can Platform Events or CDC help manage stale cache in LWC?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'standard', 'mid'),
    ('how-would-you-securely-handle-docusign-oauth-tokens-in-a-sal', 'How would you securely handle DocuSign OAuth tokens in a Salesforce LWC initiated integration?', 'Assesses your ability to reason through docusign integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-track-the-status-of-a-docusign-envelope-and-en', 'How would you track the status of a DocuSign envelope and ensure Salesforce records are updated once the document is signed?', 'Assesses your ability to reason through docusign integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('if-multiple-recipients-must-sign-in-a-defined-order-how-woul', 'If multiple recipients must sign in a defined order, how would you design the envelope and route the signing flow through OmniScript and DocuSign?', 'Assesses your ability to reason through docusign integrations constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-handle-errors-returned-from-the-docusign-api-e', 'How would you handle errors returned from the DocuSign API (e.g., invalid recipient, template not found) in OmniScript or LWC?', 'Assesses your ability to reason through docusign integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-do-you-securely-send-data-from-your-lwc-to-an-iframe-on', 'How do you securely send data from your LWC to an iframe on a different domain without exposing sensitive data?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('if-messages-sent-from-your-lwc-to-a-partner-iframe-are-silen', 'If messages sent from your LWC to a partner iframe are silently failing, what 3 checks will you perform first?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-an-lwc-embedded-in-a-visualforce-page-different-doma', 'How can an LWC embedded in a Visualforce page (different domain) reliably listen to parent page events?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('what-security-measures-would-you-enforce-to-prevent-cross-si', 'What security measures would you enforce to prevent cross-site attacks when using postMessage in LWC?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('how-would-you-communicate-between-an-lwc-and-a-third-party-p', 'How would you communicate between an LWC and a third party page inside an iframe?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'scenario', 'mid'),
    ('how-can-you-fix-the-issue-if-named-credentials-not-refreshin', 'How can you fix the issue if Named Credentials not refreshing tokens ?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('how-can-you-debug-if-external-system-returns-401-unauthorize', 'How can you debug if External system returns 401 Unauthorized to Salesforce callout even with correct Named Credential ?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('governor-limits-breached-mid-transaction-what-might-be-the-r', 'Governor limits breached mid transaction , What might be the Root cause ?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'scenario', 'senior'),
    ('apex-callouts-using-named-credentials-throw-invalid-session', 'Apex callouts using Named Credentials throw INVALID_SESSION_ID how would you resolve?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('why-might-a-named-credential-with-refresh-token-flow-fail-af', 'Why might a Named Credential with refresh token flow fail after 90 days with Google APIs?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('lwc-sets-boolean-property-but-it-reads-as-undefined-why', 'LWC sets boolean property, but it reads as undefined. Why?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'code_review', 'mid'),
    ('the-child-emits-event-with-bubbling-composed-but-parent-does', 'The Child emits event with bubbling/composed, but parent doesn''t receive it. Why?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'code_review', 'mid'),
    ('there-is-a-scenario-where-customevent-is-dispatched-but-even', 'There is a scenario where CustomEvent is dispatched, but event.target is null , how can you fix it ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('even-lms-message-is-published-but-subscriber-gets-undefined', 'Even LMS message is published but subscriber gets undefined. What might be the issue here?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'code_review', 'mid'),
    ('custom-event-payload-arrives-as-object-object-what-is-the-is', 'Custom event payload arrives as [object Object]. What is the issue here ?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'code_review', 'mid'),
    ('custom-setting-values-are-returning-null-inconsistently-what', 'Custom Setting values are returning null inconsistently. What''s going wrong ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'code_review', 'mid'),
    ('apex-logic-is-skipping-expected-validation-rule-errors-why-t', 'Apex logic is skipping expected validation rule errors. Why this is happening and how can you fix this ?', 'Assesses your ability to reason through flow automation patterns constraints in Salesforce.', 'code_review', 'mid'),
    ('apex-run-time-varies-drastically-for-the-same-data-volume-wh', 'Apex run time varies drastically for the same data volume. What''s causing the fluctuation ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('you-re-hitting-too-many-callouts-100-error-what-s-the-resolu', 'You''re hitting Too many callouts: 100 error. What''s the resolution?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('a-soql-query-returns-significantly-more-records-in-productio', 'A SOQL query returns significantly more records in production than sandbox . What''s the Fix ?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'scenario', 'senior'),
    ('i-have-to-delete-300-000-obsolete-records-from-a-custom-obje', 'I have to delete 300,000 obsolete records from a custom object. I don''t want to use Batch Apex, and I can''t use Bulk API because of org policy. How do I do this using regular Apex code?\" - Air Asia asked this to one of my student?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'scenario', 'mid')
) as seed(slug, title, summary, question_type, seniority_level)
on conflict (slug) do update
set
  title = excluded.title,
  summary = excluded.summary,
  question_type = excluded.question_type,
  seniority_level = excluded.seniority_level,
  status = 'published'::public.content_status,
  published_at = coalesce(public.questions.published_at, excluded.published_at),
  updated_at = timezone('utc', now());

-- Questions chunk 2
insert into public.questions (slug, title, summary, question_type, seniority_level, status, published_at)
select
  seed.slug, seed.title, seed.summary, seed.question_type, seed.seniority_level,
  'published'::public.content_status, timezone('utc', now())
from (
  values
    ('what-would-happen-if-you-use-offset-in-soql-for-pagination-b', 'What would happen if you use OFFSET in SOQL for pagination beyond 2,000 records? - Asked in a recent Interview?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'mid'),
    ('what-if-you-use-wire-getpicklistvalues-but-forget-to-include', 'What if you use @wire (getPicklistValues) but forget to include the correct RecordTypeId ? - Repeatedly asked in Interviews?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'code_review', 'mid'),
    ('a-nightly-process-inserts-200-000-leads-via-integration-a-be', 'A nightly process inserts 200,000 leads via integration. A before insert trigger enriches them with Account data, but the integration often fails with \"Too many SOQL queries.\" How do you make the enrichment bulk-safe without dropping the logic?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('what-would-happen-if-you-performed-a-limit-2000-soql-query-a', 'What would happen if you performed a LIMIT 2000 SOQL query and tried to paginate on the client side using that result?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-call-refreshapex-but-don-t-keep-a-refere', 'What happens if you call refreshApex() but don''t keep a reference to the wired result object?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-put-a-large-console-log-inside-renderedc', '. What happens if you put a large console.log() inside renderedCallback() without any condition?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'code_review', 'mid'),
    ('what-happens-if-your-lwc-component-has-an-infinite-loop-of-p', 'What happens if your LWC component has an infinite loop of property updates between parent and child via @api?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'code_review', 'mid'),
    ('how-do-you-ensure-an-apex-class-can-run-in-both-synchronous', 'How do you ensure an Apex class can run in both synchronous and asynchronous contexts?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-try-to-send-20-000-emails-in-a-single-tr', 'What happens if you try to send 20,000 emails in a single transaction using Messaging.sendEmail()?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-call-system-debug-with-a-very-large-stri', 'What happens if you call System.debug() with a very large string (e.g., 10 MB) in a production org?', 'Assesses your ability to reason through debugging and monitoring constraints in Salesforce.', 'standard', 'senior'),
    ('how-do-you-handle-retries-in-salesforce-when-an-external-sys', 'How do you handle retries in Salesforce when an external system is temporarily unavailable?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-secure-outbound-callouts-without-exposing-credent', 'How do you secure outbound callouts without exposing credentials in Apex code?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-enforce-api-rate-limits-in-integrations', 'How do you enforce API rate limits in integrations?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-use-json-stringify-on-a-proxy-object-ret', 'What happens if you use JSON.stringify() on a proxy object returned from a @wire?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-your-lwc-imports-a-custom-label-that-is-late', 'What happens if your LWC imports a Custom Label that is later deleted from the org?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-wire-a-method-to-an-apex-class-that-perf', 'What happens if you wire a method to an Apex class that performs heavy SOQL in connectedCallback() and also call it imperatively on button click without caching?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'junior'),
    ('what-happens-if-you-enqueue-a-queueable-job-from-inside-anot', 'What happens if you enqueue a Queueable job from inside another Queueable job without implementing System.isQueueable() checks?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-call-schema-describesobjects-for-1-000-o', 'What happens if you call Schema.describeSObjects() for 1,000+ objects in a single transaction?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-handle-bulk-dml-failures-when-one-record-fails-bu', 'How do you handle bulk DML failures when one record fails but others should still be committed?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-the-external-api-you-are-calling-sends-a-302', 'What happens if the external API you are calling sends a 302 redirect and your callout does not handle it?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-avoid-callout-timeouts-when-sending-large-payload', 'How do you avoid callout timeouts when sending large payloads to an external system?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'senior'),
    ('what-happens-if-an-integration-api-returns-mixed-success-and', 'What happens if an integration API returns mixed success and error results for a bulk request?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-an-api-returns-a-429-too-many-requests-statu', 'What happens if an API returns a 429 (Too Many Requests) status but doesn''t include a Retry After header?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'senior'),
    ('how-would-you-validate-file-types-and-sizes-before-uploading', 'How would you validate file types and sizes before uploading in LWC?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-provide-a-file-preview-e-g-pdf-viewer-image-th', 'How would you provide a file preview (e.g., PDF viewer, image thumbnail) to the user?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-handle-large-file-uploads-to-salesforce-ensuri', 'How would you handle large file uploads to Salesforce, ensuring performance and reliability?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-subscribe-to-and-handle-salesforce-platform-ev', 'How would you subscribe to and handle Salesforce Platform Events in LWC?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-ensure-that-multiple-components-consuming-the', 'How would you ensure that multiple components consuming the same event remain in sync?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-handle-scenarios-where-the-user-s-session-disc', 'How would you handle scenarios where the user''s session disconnects from the event stream?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-retrieve-and-display-the-current-approval-stat', 'How would you retrieve and display the current approval status and pending approvers in LWC?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-implement-custom-logic-for-approve-reject-acti', 'How would you implement custom logic for approve/reject actions while still respecting Salesforce approval rules?', 'Assesses your ability to reason through flow automation patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-provide-real-time-feedback-to-the-user-after-a', 'How would you provide real time feedback to the user after an approval/rejection action (e.g., toast, UI refresh)?', 'Assesses your ability to reason through flow automation patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('if-you-dispatch-a-customevent-from-a-child-but-forget-to-set', 'If you dispatch a CustomEvent from a child but forget to set bubbles:true, composed:true, will the parent component catch it?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-would-you-handle-a-scenario-where-a-parent-passes-a-very', 'How would you handle a scenario where a parent passes a very large JSON object to a child LWC multiple times?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-you-use-for-each-without-specifying-a-unique', 'What happens if you use for:each without specifying a unique key attribute while rendering a list?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'mid'),
    ('in-a-future-method-what-happens-if-you-exceed-soql-query-lim', 'In a future method, what happens if you exceed SOQL query limits while fetching related records?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('if-two-users-update-the-same-record-at-the-exact-same-time-v', 'If two users update the same record at the exact same time via Apex, how does Salesforce handle it ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('if-you-keep-appending-strings-inside-a-loop-without-using-st', 'If you keep appending strings inside a loop without using StringBuilder, what happens when heap size is exceeded?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'standard', 'mid'),
    ('if-salesforce-receives-a-malformed-json-payload-from-an-exte', 'If Salesforce receives a malformed JSON payload from an external REST API, how will JSON.deserialize behave?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('if-salesforce-is-making-a-callout-to-a-system-that-takes-2-m', 'If Salesforce is making a callout to a system that takes 2 minutes to respond, but the Salesforce timeout is 120 seconds, what happens?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'senior'),
    ('what-happens-if-an-outbound-message-fails-because-the-extern', 'What happens if an outbound message fails because the external endpoint is down?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-send-large-json-payloads-efficiently-from-salesfo', 'How do you send large JSON payloads efficiently from Salesforce to an external API ?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-two-components-on-the-same-page-import-the-s', 'What happens if two components on the same page import the same Custom Permission but one is deleted from the org?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-dispatch-a-custom-event-from-a-child-lwc', 'What happens if you dispatch a custom event from a child LWC but the parent listens with the wrong case in the event name?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-promise-all-behave-in-lwc-if-one-of-the-wired-apex', 'How does Promise.all() behave in LWC if one of the wired Apex calls fails with an unhandled rejection?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-call-a-future-method-inside-a-batch-fini', 'What happens if you call a @future method inside a batch finish() method and the batch fails halfway?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-apex-handle-database-saveresult-if-you-perform-an-i', 'How does Apex handle Database.saveResult if you perform an insert with partial failures and don''t check the isSuccess() flag?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-enqueue-a-batchable-job-inside-a-queueab', 'What happens if you enqueue a Batchable job inside a Queueable and the batch internally schedules another Schedulable?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-trigger-throws-an-unhandled-exception-in-a', 'What happens if a trigger throws an unhandled exception in an after insert context?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-two-triggers-on-the-same-object-update-the-s', 'What happens if two triggers on the same object update the same field differently in before update context?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-schedule-100-batch-jobs-in-one-transacti', 'What happens if you schedule 100 batch jobs in one transaction from a trigger?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-exceed-the-daily-api-request-limit-in-sa', 'What happens if you exceed the daily API request limit in Salesforce?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-named-credentials-help-simplify-authentication-in-in', 'How can Named Credentials help simplify authentication in integrations?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-an-external-api-you-call-returns-a-500-inter', 'What happens if an external API you call returns a 500 Internal Server Error?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-manage-partial-failures-when-an-api-sends-100-rec', 'How do you manage partial failures when an API sends 100 records to Salesforce but only 90 succeed?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-design-an-lwc-that-can-easily-handle-slow-api', 'How would you design an LWC that can easily handle slow API responses (e.g., showing spinners, async retries, or fallback data)?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-design-an-lwc-that-prevents-duplicate-api-call', 'How would you design an LWC that prevents duplicate API calls when a user clicks a button multiple times quickly?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'senior'),
    ('your-lwc-calls-an-api-that-returns-20-000-records-rendering', 'Your LWC calls an API that returns 20,000 records. Rendering them directly freezes the browser. How would you handle this scenario?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-you-use-track-incorrectly-on-a-non-primitive', 'What happens if you use @track incorrectly on a non primitive field and mutate it directly without reassignment?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('if-a-parent-lwc-uses-api-property-to-pass-data-but-forgets-t', 'If a parent LWC uses @api property to pass data but forgets to bind it, how does the child behave?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-lwc-handle-multiple-wired-methods-calling-the-same', 'How does LWC handle multiple wired methods calling the same Apex class simultaneously?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-call-a-queueable-inside-another-queueabl', 'What happens if you call a Queueable inside another Queueable repeatedly in a loop?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('if-you-use-database-insert-records-false-with-partial-failur', 'If you use Database.insert(records, false) with partial failures, how do failed records impact governor limits?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'senior'),
    ('what-happens-if-you-call-system-debug-limits-getqueries-insi', 'What happens if you call System.debug(Limits.getQueries()) inside a recursive trigger?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-before-trigger-updates-the-same-record-fie', 'What happens if a before trigger updates the same record field that an after trigger also tries to modify?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('if-multiple-triggers-exist-on-the-same-object-in-what-order', 'If multiple triggers exist on the same object, in what order do they execute?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-call-system-enqueuejob-inside-a-trigger', 'What happens if you call System.enqueueJob() inside a trigger for every record in bulk insert?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-an-http-callout-exceeds-the-120-second-timeo', 'What happens if an HTTP callout exceeds the 120-second timeout in Apex?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'senior'),
    ('if-the-external-system-s-tls-certificate-expires-how-does-sa', 'If the external system''s TLS certificate expires, how does Salesforce integration behave?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('how-does-salesforce-handle-large-json-responses-10mb-in-an-h', 'How does Salesforce handle large JSON responses (10MB+) in an HTTP callout?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('your-lwc-fetches-15mb-json-data-from-an-external-api-the-res', 'Your LWC fetches 15MB JSON data from an external API. The response takes 10+ seconds and sometimes times out. How would you optimize both backend and frontend handling? - Recently Asked in KPMG?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-design-a-search-component-in-lwc-that-avoids-u', 'How would you design a search component in LWC that avoids unnecessary server calls while the user is typing?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('you-have-a-callout-from-apex-that-sometimes-exceeds-the-120', 'You have a callout from Apex that sometimes exceeds the 120 second timeout due to slow external API response. How would you design a reliable, retry safe solution? - Recently asked in EY?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'senior'),
    ('how-lwc-makes-a-call-to-an-apex-method-that-queries-200k-rec', 'How LWC makes a call to an Apex method that queries 200k records. The UI freezes for (8-10 seconds) before rendering. How would you design both Apex and LWC to improve performance? - Recently Asked in an Interview?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'scenario', 'architect'),
    ('your-lwc-sales-dashboard-crunches-200k-account-and-opportuni', 'Your LWC sales dashboard crunches 200k+ Account and Opportunity records but executives face (8-10 second) UI freezes and tab crashes on load. The dashboard needs to display aggregated insights, top performers, and drill downs all with a smooth, responsive experience. How would you fix it?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'architect'),
    ('your-apex-call-returns-2mb-json-data-that-must-be-sorted-fil', 'Your Apex call returns 2MB JSON data that must be sorted, filtered, and grouped before rendering. How would you design the Apex component ? - Recently Asked in an Interview?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('you-need-to-call-an-external-api-that-accepts-only-100-reque', 'You need to call an external API that accepts only 100 requests per minute, but your org may trigger thousands. How do you throttle or batch these calls efficiently? - An Interview Question That Caught My Attention Recently?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('you-re-building-a-dashboard-lwc-that-aggregates-data-from-5', 'You''re building a dashboard LWC that aggregates data from 5 different objects. How would you structure Apex and caching to improve performance?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-design-an-lwc-that-prevents-multiple-identical', 'How would you design an LWC that prevents multiple identical API calls made within a short time window even if triggered from different components? - A Common Interview Scenario That Confuses Many Devs?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-design-the-apex-callout-to-the-external-api-wh', 'How would you design the Apex callout to the external API while ensuring the transaction is not delayed or blocked?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-handle-failed-validations-or-api-timeouts-grac', 'How would you handle failed validations or API timeouts gracefully in the UI ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-secure-api-credentials-and-manage-authenticati', 'How would you secure API credentials and manage authentication in Salesforce?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-would-you-design-this-bidirectional-sync-to-ensure-data', 'How would you design this bidirectional sync to ensure data consistency and avoid duplicates?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-handle-callout-limits-if-multiple-orders-are-c', 'How would you handle callout limits if multiple orders are created simultaneously?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-design-the-retry-mechanism-for-failed-callouts', 'How would you design the retry mechanism for failed callouts or ERP unavailability?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'senior'),
    ('based-on-total-opportunity-revenue-using-only-one-aggregatio', 'based on total Opportunity revenue, using only one aggregation query ?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'mid'),
    ('your-query-on-opportunitylineitem-is-running-through-8-milli', 'Your query on OpportunityLineItem is running through 8 million records , how would you improve its performance using custom indexes?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'scenario', 'mid'),
    ('you-must-perform-cross-object-filtering-account-case-product', 'You must perform cross object filtering (Account Case Product__c) in one SOQL like query . How will you do it in Apex ?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'scenario', 'architect'),
    ('you-re-processing-customer-payments-through-a-rest-api-like', 'You''re processing customer payments through a REST API (like Stripe or Razorpay). How do you ensure that if the payment succeeds externally but fails to update in Salesforce, you don''t double charge the user?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-track-failed-transactions-and-reprocess-them-l', 'How would you track failed transactions and reprocess them later without duplicating successful ones?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-design-an-apex-rest-endpoint-to-receive-and-va', 'How would you design an Apex REST endpoint to receive and validate these securely ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-implement-platform-events-or-streaming-api-in', 'How would you implement Platform Events or Streaming API in LWC to keep data in sync?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-design-your-lwc-without-breaking-in-production', 'How would you design your LWC without breaking in production?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-efficiently-share-state-between-multiple-lwcs', 'How would you efficiently share state between multiple LWCs without using the parent component ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-you-validate-a-signed-request-in-apex-to-ensure-the', 'How can you validate a signed request in Apex to ensure the payload hasn''t been tampered with?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-are-common-causes-of-invalid-signature-errors-during-jw', 'What are common causes of \"invalid signature\" errors during JWT authentication and how would you debug them?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'standard', 'junior'),
    ('you-have-to-send-confirmation-emails-to-1m-contacts-after-a', 'You have to send confirmation emails to 1M Contacts after a data migration , how would you design this without hitting limits?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'architect'),
    ('how-do-you-handle-duplicate-webhook-requests-in-apex-to-avoi', 'How do you handle duplicate webhook requests in Apex to avoid processing the same request twice ?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('your-apex-rest-api-receives-thousands-of-records-per-request', 'Your Apex REST API receives thousands of records per request , how do you handle partial failures and ensure no data loss?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('salesforce-must-send-data-to-an-external-api-that-goes-down', 'Salesforce must send data to an external API that goes down intermittently , how would you ensure delivery once it''s back online?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid')
) as seed(slug, title, summary, question_type, seniority_level)
on conflict (slug) do update
set
  title = excluded.title,
  summary = excluded.summary,
  question_type = excluded.question_type,
  seniority_level = excluded.seniority_level,
  status = 'published'::public.content_status,
  published_at = coalesce(public.questions.published_at, excluded.published_at),
  updated_at = timezone('utc', now());

-- Questions chunk 3
insert into public.questions (slug, title, summary, question_type, seniority_level, status, published_at)
select
  seed.slug, seed.title, seed.summary, seed.question_type, seed.seniority_level,
  'published'::public.content_status, timezone('utc', now())
from (
  values
    ('the-external-api-s-ssl-certificate-rotates-every-3-months-ho', 'The external API''s SSL certificate rotates every 3 months , how do you handle this automatically in Salesforce?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('you-need-to-integrate-with-a-third-party-that-only-supports', 'You need to integrate with a third party that only supports OAuth 2.0 authorization code flow , how can Salesforce authenticate without manual user consent?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('your-external-service-uses-jwt-based-authentication-how-woul', 'Your external service uses JWT based authentication , how would you generate and refresh tokens securely from Apex?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'scenario', 'mid'),
    ('how-would-you-design-an-lwc-that-cancels-an-ongoing-api-call', 'How would you design an LWC that cancels an ongoing API call if the user changes a filter before the first response arrives? - A tricky interview question?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('how-would-you-design-an-lwc-that-merges-multiple-api-calls-f', 'How would you design an LWC that merges multiple API calls from different components into one batched Apex callout? - The One Interview Topic You Can''t Afford to Miss?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'senior'),
    ('what-happens-if-you-use-api-on-a-getter-but-forget-the-corre', 'What happens if you use @api on a getter but forget the corresponding setter?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-failure-occurs-when-an-lwc-tries-to-render-a-list-using', 'What failure occurs when an LWC tries to render a list using a non unique key in for:each?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-two-child-lwcs-mutate-the-same-reactive-obje', 'What happens if two child LWCs mutate the same reactive object received from a parent simultaneously?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-you-try-json-deserialize-a-payload-that-cont', 'What happens if you try JSON.deserialize a payload that contains extra fields not present in your Apex class?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-too-many-chained-queueables-cause-the-maximu', 'What happens if too many chained Queueables cause the \"Maximum stack depth\" error?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('if-batch-finish-method-throws-an-unhandled-exception-what-ha', 'If batch finish() method throws an unhandled exception, what happens to the job status?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-trigger-tries-to-update-a-field-that-has-a', 'What happens if a trigger tries to update a field that has a workflow field update on the same field?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-salesforce-behave-if-two-triggers-both-re-query-rec', 'How does Salesforce behave if two triggers both re query records inside the same transaction?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'mid'),
    ('if-a-trigger-calls-a-queueable-that-updates-the-same-object', 'If a trigger calls a Queueable that updates the same object, how does it impact transaction boundaries?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-salesforce-handle-a-callout-where-the-http-response', 'How does Salesforce handle a callout where the HTTP response contains malformed JSON?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-named-credentials-rotate-their-oauth-token-i', 'What happens if Named Credentials rotate their OAuth token in the middle of a running batch job?', 'Assesses your ability to reason through oauth and named credentials constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-salesforce-behave-if-the-external-system-returns-a', 'How does Salesforce behave if the external system returns a paginated dataset without a next page URL?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('a-trigger-on-case-uses-callouts-to-an-external-system-in-bul', 'A trigger on Case uses callouts to an external system. In bulk operations (100 records), callouts fail. You cannot move logic to a Flow or Platform Event. How do you solve this? - Air Asia asked this in a Recent Technical Round?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'mid'),
    ('your-apex-returns-a-json-payload-of-1-mb-and-the-browser-tak', 'Your Apex returns a JSON payload of 1 MB and the browser takes 3-5 seconds to parse it. How do you restructure the response to minimize parsing overhead? - The One Technical Concept You Must Know Before Your Interview?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('design-an-lwc-that-loads-200-fields-but-renders-only-the-vis', 'Design an LWC that loads 200+ fields but renders only the visible viewport fields (virtual scrolling) to avoid lag?', 'Assesses your ability to reason through lwc data and performance constraints in Salesforce.', 'scenario', 'senior'),
    ('an-apex-trigger-calls-an-external-service-to-validate-addres', 'An Apex trigger calls an external service to validate addresses. In a bulk update of 200 records, only 10% validation is needed. The rest are duplicates or unchanged. How do you reduce callout volume using Apex patterns? - A Crucial concept IBM asked last Week to filter good candidates?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('the-payment-api-sometimes-completes-the-charge-but-your-apex', 'The Payment API sometimes completes the charge, but your Apex callout hits a timeout. How do you make sure so the user is never double charged? - Recently asked in a Visa Sponsored Technical round?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'scenario', 'senior'),
    ('your-apex-callout-times-out-at-120-seconds-but-the-payment-p', 'Your Apex callout times out at 120 seconds, but the payment provider still completes the charge. A retry would double charge the customer. How do you design the integration so the payment is processed only once even if the response is lost?', 'Assesses your ability to reason through payment integrations constraints in Salesforce.', 'scenario', 'senior'),
    ('an-lwc-renders-correctly-in-lightning-app-builder-but-fails', 'An LWC renders correctly in Lightning App Builder but fails inside a Flow Screen. Why?', 'Assesses your ability to reason through lwc and flow integration constraints in Salesforce.', 'code_review', 'mid'),
    ('an-lwc-shows-stale-data-after-record-update-even-though-refr', 'An LWC shows stale data after record update, even though refreshApex() is called. What could still prevent fresh data?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'code_review', 'mid'),
    ('a-child-component-emits-a-customevent-but-the-parent-never-r', 'A child component emits a CustomEvent, but the parent never receives it. The event name looks correct. What is the issue ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'code_review', 'mid'),
    ('an-apex-class-successfully-deserializes-json-but-some-fields', 'An Apex class successfully deserializes JSON, but some fields are always null even though they exist in the payload. What could be wrong?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'code_review', 'mid'),
    ('a-queueable-job-is-enqueued-from-another-queueable-repeatedl', 'A Queueable job is enqueued from another Queueable repeatedly under a conditional loop. Why can this fail in production but pass in sandbox?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'code_review', 'mid'),
    ('what-happens-if-an-apex-transaction-exceeds-cpu-time-after-d', 'What happens if an Apex transaction exceeds CPU time after DML but before commit?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'standard', 'mid'),
    ('a-queueable-enqueues-another-queueable-conditionally-why-can', 'A Queueable enqueues another Queueable conditionally. Why can this work in tests but fail intermittently in production?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'code_review', 'mid'),
    ('a-trigger-updates-a-record-which-fires-another-trigger-on-th', 'A trigger updates a record, which fires another trigger on the same object. No recursion guard exists, yet it doesn''t go into infinite loop. Why?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'code_review', 'mid'),
    ('a-batch-apex-job-finishes-with-status-completed-but-some-bat', 'A Batch Apex job finishes with status \"Completed\", but some batch chunks never processed. How is this possible?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'code_review', 'mid'),
    ('what-happens-if-a-callout-timeout-occurs-after-the-external', 'What happens if a callout timeout occurs after the external system has already processed the request?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'senior'),
    ('a-callout-succeeds-http-200-but-the-integration-still-fails', 'A callout succeeds (HTTP 200) but the integration still fails functionally. What non obvious checks should you perform?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'code_review', 'mid'),
    ('an-external-api-returns-partial-data-with-no-error-code-how', 'An external API returns partial data with no error code. How should Apex defensively handle this scenario?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-refreshapex-is-called-but-the-wired-method-p', 'What happens if refreshApex() is called but the wired method parameters haven''t changed?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-lwc-reactivity-behave-when-a-nested-property-of-a-t', 'How does LWC reactivity behave when a nested property of a @track object is mutated?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('why-are-callouts-after-dml-restricted-in-synchronous-apex', 'Why are callouts after DML restricted in synchronous Apex?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('is-invoking-a-future-method-from-batch-apex-considered-unsaf', 'Is invoking a future method from Batch Apex considered unsafe or Safe ?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('how-is-a-custom-event-handled-if-it-is-dispatched-before-the', 'How is a custom event handled if it is dispatched before the component is connected to the DOM?', 'Assesses your ability to reason through lwc component communication constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-updating-a-field-in-a-before-update-trigger-sometim', 'Why does updating a field in a before update trigger sometimes fail to persist after commit?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-queueable-enqueues-another-queueable-durin', 'What happens if a Queueable enqueues another Queueable during test execution?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-the-external-api-changes-response-schema-wit', 'What happens if the external API changes response schema without versioning?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-trigger-oldmap-contain-values-that-were-never-visibl', 'How can Trigger.oldMap contain values that were never visible to users?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'code_review', 'mid'),
    ('why-do-static-variables-fail-to-prevent-recursion-in-batch-a', 'Why do static variables fail to prevent recursion in Batch Apex invoked triggers?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-an-apex-getter-return-different-values-in-the-same-t', 'Why can an Apex getter return different values in the same transaction?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-trigger-oldmap-contain-values-that-never-existed-in', 'How can Trigger.oldMap contain values that never existed in the database?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'code_review', 'mid'),
    ('why-do-static-variables-reset-between-batch-execute-chunks', 'Why do static variables reset between batch execute chunks?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-test-stoptest-execute-jobs-in-a-different-order-than', 'Why can Test.stopTest() execute jobs in a different order than production?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'senior'),
    ('why-does-apex-with-with-sharing-still-expose-records-in-some', 'Why does Apex with with sharing still expose records in some async contexts?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'standard', 'mid'),
    ('what-breaks-if-the-api-responds-with-http-200-but-returns-a', 'What breaks if the API responds with HTTP 200 but returns a logical error in the body?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-json-deserialization-fail-even-when-field-names-mat', 'Why does JSON deserialization fail even when field names match?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('why-might-be-the-reason-that-a-callout-succeed-in-sandbox-bu', 'Why might be the reason that a callout succeed in sandbox but fail in production?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'senior'),
    ('why-do-record-visibility-rules-behave-differently-in-reports', 'Why do record visibility rules behave differently in reports vs Apex?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-with-sharing-class-calls-a-without-sharing', 'What happens if a with sharing class calls a without sharing helper class?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-a-trigger-fire-twice-for-a-single-user-action-withou', 'Why can a trigger fire twice for a single user action without recursion?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-a-formula-field-value-differ-when-accessed-from-ape', 'Why does a formula field value differ when accessed from Apex vs reported in a Flow?', 'Assesses your ability to reason through flow automation patterns constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-without-sharing-not-bypass-object-level-security-in', 'Why does without sharing not bypass object level security in all contexts?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'standard', 'mid'),
    ('c-reports-show-records-that-apex-cannot-access', 'C reports show records that Apex cannot access?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-duplicate-rules-behave-differently-in-apex-vs-data-l', 'Why can duplicate rules behave differently in Apex vs Data Loader?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-when-a-with-sharing-class-invokes-a-without-sha', 'What happens when a with sharing class invokes a without sharing Queueable?', 'Assesses your ability to reason through crud, fls, and sharing constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-mutating-a-nested-property-of-a-track-object-not-tr', 'Why does mutating a nested property of a @track object not trigger re-rendering?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-trigger-old-sometimes-reflect-values-that-were-neve', 'Why does Trigger.old sometimes reflect values that were never committed?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-an-api-integration-succeed-when-called-manually-but', 'Why does an API integration succeed when called manually but fail when invoked from a trigger?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('why-does-api-data-arrive-after-connectedcallback', 'Why does @api data arrive after connectedCallback()?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'junior'),
    ('what-happens-if-a-customevent-is-dispatched-before-the-paren', 'What happens if a CustomEvent is dispatched before the parent is connected to the DOM?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-breaks-if-an-external-api-returns-http-204-with-a-non-e', 'What breaks if an external API returns HTTP 204 with a non-empty body?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-an-lwc-re-render-without-any-tracked-property-chang', 'Why does an LWC re render without any tracked property change?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-test-starttest-reset-limits-but-not-static-memory-i', 'Why does Test.startTest() reset limits but not static memory in certain cases?', 'Assesses your ability to reason through apex testing constraints in Salesforce.', 'standard', 'mid'),
    ('trigger-oldmap-contains-a-field-value-that-was-never-committ', 'Trigger.oldMap contains a field value that was never committed to the database. How is this possible?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'code_review', 'mid'),
    ('why-can-a-batch-apex-finish-method-see-data-that-execute-nev', 'Why can a Batch Apex finish() method see data that execute() never processed?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-trigger-new-sometimes-contain-records-that-fail-val', 'Why does Trigger.new sometimes contain records that fail validation later?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-refreshapex-is-called-inside-a-renderedcallb', 'What happens if refreshApex() is called inside a renderedCallback repeatedly?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('why-do-named-credentials-work-for-rest-but-fail-for-soap-end', 'Why do Named Credentials work for REST but fail for SOAP endpoints?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-a-callout-from-a-trigger-work-in-sandbox-but-fail-i', 'Why does a callout from a trigger work in sandbox but fail in production?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'senior'),
    ('why-should-dom-access-be-avoided-in-connectedcallback', 'Why should DOM access be avoided in connectedCallback()?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'junior'),
    ('what-happens-if-a-child-fires-an-event-but-the-parent-isn-t', 'What happens if a child fires an event but the parent isn''t rendered yet?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-record-is-deleted-while-an-lwc-is-still-wi', 'What happens if a record is deleted while an LWC is still wired to it?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-a-soql-query-return-different-results-inside-the-sam', 'Why can a SOQL query return different results inside the same transaction?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-an-external-api-returns-http-200-but-with-a', 'What happens if an external API returns HTTP 200 but with a business level error in the payload?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('an-lwc-makes-an-imperative-apex-call-triggered-by-user-actio', 'An LWC makes an imperative Apex call triggered by user actions. Users double click rapidly and duplicate requests hit the server. How would you design the component to prevent this without blocking the UI? - Recently asked in a Visa Sponsored round?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('salesforce-needs-to-send-a-massive-json-payload-but-heap-siz', 'Salesforce needs to send a massive JSON payload, but heap size and callout limits are screaming. How would you solve this? - Recently asked in an Interview?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-a-child-dispatches-an-event-before-the-paren', 'What happens if a child dispatches an event before the parent is rendered?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('how-is-a-component-affected-when-it-re-renders-inside-a-for', 'How is a component affected when it re renders inside a for:each loop?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'mid'),
    ('how-does-salesforce-handle-callout-responses-that-arrive-aft', 'How does Salesforce handle callout responses that arrive after a timeout?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'senior'),
    ('why-can-the-same-soql-query-return-different-results-within', 'Why can the same SOQL query return different results within one transaction?', 'Assesses your ability to reason through soql and dml optimization constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-future-method-is-invoked-from-another-asyn', 'What happens if a future method is invoked from another async context?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('why-why-not-are-callouts-not-allowed-after-partial-dml-opera', 'Why/Why not are callouts not allowed after partial DML operations?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-a-batch-apex-job-is-aborted-while-an-execute', 'What happens if a Batch Apex job is aborted while an execute() is in progress?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('why-does-a-before-insert-trigger-not-have-record-ids-but-aft', 'Why does a before insert trigger not have record IDs but after insert does?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('you-have-an-lwc-with-a-tracked-object-if-the-component-reass', 'You have an LWC with a tracked object. If the component reassigns the same reference to that object, how will the UI behave?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('an-external-api-changes-its-response-format-without-notice-h', 'An external API changes its response format without notice. How should your callout handling adapt?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-a-trigger-on-a-platform-event-performs-dml', 'What happens if a trigger on a Platform Event performs DML?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-finish-enqueues-another-batch-or-queueable-j', 'What happens if finish() enqueues another Batch or Queueable job?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('tell-me-about-a-time-you-handled-a-production-issue-under-pr', 'Tell me about a time you handled a production issue under pressure. How did you manage it?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'standard', 'senior'),
    ('how-do-you-explain-technical-solutions-to-non-technical-clie', 'How do you explain technical solutions to non technical clients?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'standard', 'mid'),
    ('imagine-a-client-has-unrealistic-expectations-on-delivery-ti', 'Imagine a client has unrealistic expectations on delivery timelines how would you handle it?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'standard', 'mid'),
    ('describe-a-situation-where-you-worked-with-multiple-teams-ha', 'Describe a situation where you worked with multiple teams having conflicting priorities. How did you manage deadlines?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'standard', 'mid'),
    ('what-is-connectedcallback', 'What is connectedCallback()?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'junior'),
    ('what-are-decorators-in-lwc', 'What are decorators in LWC?', 'Assesses your ability to reason through lwc rendering lifecycle constraints in Salesforce.', 'standard', 'junior')
) as seed(slug, title, summary, question_type, seniority_level)
on conflict (slug) do update
set
  title = excluded.title,
  summary = excluded.summary,
  question_type = excluded.question_type,
  seniority_level = excluded.seniority_level,
  status = 'published'::public.content_status,
  published_at = coalesce(public.questions.published_at, excluded.published_at),
  updated_at = timezone('utc', now());

-- Questions chunk 4
insert into public.questions (slug, title, summary, question_type, seniority_level, status, published_at)
select
  seed.slug, seed.title, seed.summary, seed.question_type, seed.seniority_level,
  'published'::public.content_status, timezone('utc', now())
from (
  values
    ('what-is-the-return-type-of-start-method', 'What is the return type of start method ?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'junior'),
    ('but-can-you-debug-why-cpu-time-suddenly-spikes-in-production', 'But can you debug why CPU time suddenly spikes in production after a release?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'scenario', 'senior'),
    ('or-why-a-seemingly-harmless-flow-brought-the-org-to-its-knee', 'Or why a seemingly harmless Flow brought the org to its knees?', 'Assesses your ability to reason through flow automation patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('how-do-you-design-triggers-and-flows-so-they-don-t-conflict', 'How do you design triggers and Flows so they don''t conflict with each other?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'senior'),
    ('a-trigger-works-in-sandbox-but-fails-in-production-how-do-yo', 'A trigger works in sandbox but fails in production. How do you debug it?', 'Assesses your ability to reason through debugging and monitoring constraints in Salesforce.', 'scenario', 'senior'),
    ('what-happens-if-a-future-method-throws-an-exception', 'What happens if a future method throws an exception?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('your-org-hits-cpu-time-limit-intermittently-how-do-you-ident', 'Your org hits CPU time limit intermittently. How do you identify the root cause?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-a-governor-limit-is-hit-inside-a-try-block-w', 'What happens if a governor limit is hit inside a try block , will catch execute?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'standard', 'senior'),
    ('a-deployment-fails-due-to-test-failures-in-unrelated-areas-w', 'A deployment fails due to test failures in unrelated areas. What do you do?', 'Assesses your ability to reason through apex testing constraints in Salesforce.', 'scenario', 'mid'),
    ('what-s-your-strategy-to-avoid-recursive-triggers-and-automat', 'What''s your strategy to avoid recursive triggers and automation loops?', 'Assesses your ability to reason through flow automation patterns constraints in Salesforce.', 'standard', 'junior'),
    ('an-external-integration-suddenly-starts-timing-out-how-do-yo', 'An external integration suddenly starts timing out. How do you troubleshoot it?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-an-lwc-throws-an-error-during-the-render-pha', 'What happens if an LWC throws an error during the render phase?', 'Assesses your ability to reason through lwc fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-two-lwcs-calling-the-same-apex-method-get-different', 'Why can two LWCs calling the same Apex method get different results at the same time?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'mid'),
    ('why-should-integration-logic-avoid-being-placed-directly-ins', 'Why should integration logic avoid being placed directly inside triggers?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('how-can-a-trigger-pass-all-tests-but-still-fail-at-scale-in', 'How can a trigger pass all tests but still fail at scale in production?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'scenario', 'senior'),
    ('what-happens-if-salesforce-times-out-but-the-external-system', 'What happens if Salesforce times out but the external system completes the operation?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-a-trigger-causes-a-mixed-dml-operation-indir', 'What happens if a trigger causes a mixed DML operation indirectly?', 'Assesses your ability to reason through mixed dml operations constraints in Salesforce.', 'scenario', 'mid'),
    ('can-a-rollback-undo-dml-done-by-a-future-or-queueable-job', 'Can a Rollback undo DML done by a future or Queueable job?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-the-api-version-changes-but-salesforce-code', 'What happens if the API version changes but Salesforce code is not updated?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-when-two-flows-and-a-trigger-update-the-same-fi', 'What happens when two flows and a trigger update the same field differently?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-two-batch-apex-jobs-update-the-same-records', 'What happens if two Batch Apex jobs update the same records concurrently?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'scenario', 'senior'),
    ('describe-a-situation-where-a-production-issue-was-caused-by', 'Describe a situation where a production issue was caused by your own change. How did you handle accountability?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'scenario', 'senior'),
    ('how-do-you-handle-a-teammate-who-repeatedly-breaks-productio', 'How do you handle a teammate who repeatedly breaks production but is technically strong?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'scenario', 'senior'),
    ('describe-a-situation-where-requirements-changed-mid-sprint-h', 'Describe a situation where requirements changed mid sprint. How did you adapt without derailing delivery?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-governor-limit-is-hit-inside-a-try-block-wil', 'What happens if governor limit is hit inside a try block , will catch execute ?', 'Assesses your ability to reason through governor limits constraints in Salesforce.', 'standard', 'senior'),
    ('how-do-you-handle-callouts-in-batch-or-queueable-safely', 'How do you handle callouts in batch or queueable safely ?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('trigger-logic-depends-on-field-change-how-will-you-make-sure', 'Trigger logic depends on field change , how will you make sure it runs only when field changes ?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'mid'),
    ('how-do-you-handle-scenarios-where-multiple-batch-jobs-need-t', 'How do you handle scenarios where multiple batch jobs need to run in sequence?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'scenario', 'mid'),
    ('if-platform-events-gets-processed-twice-how-would-you-fix-it', 'If Platform events gets processed twice , how would you fix it to prevent duplicates ?', 'Assesses your ability to reason through platform events and cdc constraints in Salesforce.', 'scenario', 'mid'),
    ('what-happens-if-the-start-method-returns-a-very-large-queryl', 'What happens if the start() method returns a very large QueryLocator?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('what-does-a-promise-actually-return', 'What does a Promise actually return?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'standard', 'junior'),
    ('why-are-callouts-not-allowed-after-dml-in-the-same-transacti', 'Why are callouts not allowed after DML in the same transaction?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('what-happens-if-an-lwc-wired-method-returns-data-successfull', 'What happens if an LWC wired method returns data successfully, but the component still renders an error?', 'Assesses your ability to reason through lwc wire service constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-a-trigger-pass-all-tests-but-fail-in-production-at-s', 'Why can a trigger pass all tests but fail in production at scale?', 'Assesses your ability to reason through apex triggers constraints in Salesforce.', 'standard', 'senior'),
    ('why-can-two-integrations-updating-the-same-record-at-the-sam', 'Why can two integrations updating the same record at the same time see different oldMap values?', 'Assesses your ability to reason through integration resilience patterns constraints in Salesforce.', 'standard', 'mid'),
    ('why-can-batch-apex-process-partial-data-successfully', 'Why can Batch Apex process partial data successfully?', 'Assesses your ability to reason through asynchronous apex constraints in Salesforce.', 'standard', 'mid'),
    ('we-had-a-production-issue-caused-by-a-recent-deployment-what', 'We had a production issue caused by a recent deployment. What steps will you take to identify the root cause and stabilize the system?', 'Assesses your ability to reason through debugging and monitoring constraints in Salesforce.', 'scenario', 'senior'),
    ('if-there-is-a-team-member-who-is-technically-strong-but-has', 'If there is a team member who is technically strong but has caused instability in production. How did you handle this situation?', 'Assesses your ability to reason through apex fundamentals constraints in Salesforce.', 'scenario', 'senior'),
    ('if-you-need-to-explain-a-production-failure-to-non-technical', 'If you need to explain a production failure to non technical stakeholders. What would be your next steps ?', 'Assesses your ability to reason through stakeholder and behavioral scenarios constraints in Salesforce.', 'scenario', 'senior')
) as seed(slug, title, summary, question_type, seniority_level)
on conflict (slug) do update
set
  title = excluded.title,
  summary = excluded.summary,
  question_type = excluded.question_type,
  seniority_level = excluded.seniority_level,
  status = 'published'::public.content_status,
  published_at = coalesce(public.questions.published_at, excluded.published_at),
  updated_at = timezone('utc', now());

-- PART 4b: question_topics links
-- question_topics chunk 1
insert into public.question_topics (question_id, topic_id, sort_order)
select q.id, t.id, seed.sort_order
from (
  values
    ('you-have-a-recursive-trigger-on-a-custom-object-and-under-ce', 'debugging-and-monitoring', 10),
    ('a-custom-apex-rest-service-starts-throwing-regex-too-complic', 'debugging-and-monitoring', 10),
    ('an-apex-class-uses-type-forname-and-type-newinstance-for-dyn', 'debugging-and-monitoring', 10),
    ('you-re-debugging-a-too-many-queueable-jobs-added-to-the-queu', 'integration-patterns', 10),
    ('you-have-a-method-that-runs-perfectly-in-an-anonymous-window', 'crud-fls-sharing', 10),
    ('how-do-you-ensure-atomicity-and-rollback-capabilities-when-d', 'asynchronous-apex', 10),
    ('how-would-you-implement-a-transactional-idempotent-batch-job', 'integration-patterns', 10),
    ('how-do-you-guarantee-data-consistency-and-transactional-inte', 'asynchronous-apex', 10),
    ('how-would-you-propose-to-process-hierarchical-interdependent', 'soql-and-dml-optimization', 10),
    ('how-can-you-maintain-referential-integrity-and-avoid-orphane', 'asynchronous-apex', 10),
    ('how-can-you-tackle-a-governor-limit-resilient-chain-of-queue', 'asynchronous-apex', 10),
    ('how-do-you-build-a-platform-native-retry-mesh-that-tracks-jo', 'integration-patterns', 10),
    ('how-would-you-coordinate-a-multi-pattern-async-convergence-w', 'platform-events-and-cdc', 10),
    ('how-do-you-control-job-explosion-enforce-execution-priority', 'asynchronous-apex', 10),
    ('how-do-you-enforce-distributed-rollback-coordination-across', 'asynchronous-apex', 10),
    ('since-apex-can-t-directly-receive-webhooks-how-can-you-route', 'lwc-fundamentals', 10),
    ('how-can-an-lwc-concurrently-handle-both-platform-events-and', 'platform-events-and-cdc', 10),
    ('how-would-you-design-an-lwc-that-processes-cdc-events-for-mi', 'platform-events-and-cdc', 10),
    ('how-can-you-add-retry-logic-in-an-lwc-to-handle-temporary-ap', 'lwc-fundamentals', 10),
    ('how-do-you-handle-out-of-order-cdc-events-in-lwc-when-multip', 'platform-events-and-cdc', 10),
    ('parent-uses-import-c-childcomp-for-lazy-load-child-uses-wire', 'lwc-component-communication', 10),
    ('lwc-uses-buildcustomevent-with-bubbling-composition-but-pare', 'lwc-component-communication', 10),
    ('lwc-injects-third-party-widget-in-renderedcallback-via-direc', 'lwc-rendering-lifecycle', 10),
    ('lwc-uses-lightning-record-edit-form-with-dynamic-recordid-an', 'lwc-fundamentals', 10),
    ('in-a-nested-lwc-dashboard-inline-edits-in-one-chart-don-t-re', 'lwc-data-and-performance', 10),
    ('you-built-a-reusable-datatable-with-wire-and-onsave-but-team', 'lwc-wire-service', 10),
    ('your-component-uses-track-for-data-mutations-after-edit-but', 'lwc-fundamentals', 10),
    ('multiple-lwcs-show-the-same-data-source-after-update-in-one', 'apex-fundamentals', 10),
    ('you-re-combining-getrecord-with-imperative-updates-after-sav', 'apex-fundamentals', 10),
    ('when-multiple-lwcs-subscribe-to-the-same-lightning-message-c', 'lwc-component-communication', 10),
    ('what-are-the-implications-of-caching-wire-service-data-in-lw', 'apex-fundamentals', 10),
    ('how-to-manage-component-lifecycle-issues-when-an-lwc-is-dest', 'lwc-rendering-lifecycle', 10),
    ('how-to-implement-multi-language-support-for-dynamic-field-la', 'apex-fundamentals', 10),
    ('how-to-handle-partial-page-refreshes-in-lwcs-embedded-in-aur', 'apex-fundamentals', 10),
    ('you-re-syncing-contacts-across-3-external-systems-via-platfo', 'platform-events-and-cdc', 10),
    ('contact-events-are-arriving-before-related-account-data-how', 'apex-fundamentals', 10),
    ('your-cdc-setup-handles-500k-events-daily-some-events-are-del', 'platform-events-and-cdc', 10),
    ('intermittent-timeout-errors-are-impacting-api-reliability-ho', 'apex-fundamentals', 10),
    ('given-graphql-is-in-pilot-how-would-you-design-a-performant', 'integration-patterns', 10),
    ('you-need-to-sync-5-million-product-records-between-orgs-do-y', 'platform-events-and-cdc', 10),
    ('what-are-the-key-lifecycle-events-in-a-websocket-connection', 'apex-fundamentals', 10),
    ('can-you-explain-how-lazy-loading-images-or-data-can-affect-a', 'apex-fundamentals', 10),
    ('what-are-the-security-implications-of-exposing-sensitive-dat', 'apex-fundamentals', 10),
    ('how-do-you-manage-state-effectively-across-components-in-a-l', 'lwc-data-and-performance', 10),
    ('how-do-you-integrate-custom-validation-messages-that-are-bot', 'apex-fundamentals', 10),
    ('what-s-the-best-way-to-secure-the-inbound-slack-interaction', 'slack-integrations', 10),
    ('can-you-open-a-slack-modal-from-a-button-click-in-slack-itse', 'slack-integrations', 10),
    ('how-would-you-ensure-message-delivery-to-slack-is-reliable-e', 'slack-integrations', 10),
    ('how-would-you-handle-different-slack-modals-dynamically-base', 'slack-integrations', 10),
    ('how-do-you-prevent-duplicate-slack-messages-if-the-same-plat', 'slack-integrations', 10),
    ('an-lwc-fetches-data-from-3-async-sources-apex-a-platform-eve', 'platform-events-and-cdc', 10),
    ('you-re-building-a-secure-lwc-page-that-uses-apex-to-fetch-se', 'lwc-security-and-cross-domain', 10),
    ('your-lwc-makes-a-call-to-apex-but-the-response-takes-3-secon', 'lwc-fundamentals', 10),
    ('you-need-to-load-different-versions-of-the-same-third-party', 'apex-fundamentals', 10),
    ('you-re-combining-lightning-data-service-and-custom-apex-call', 'lwc-fundamentals', 10),
    ('after-launching-a-flow-from-lwc-how-do-you-handle-the-onstat', 'lwc-flow-integration', 10),
    ('how-do-you-refresh-lwc-data-after-the-embedded-flow-updates', 'lwc-flow-integration', 10),
    ('how-can-you-start-an-embedded-flow-in-lwc-only-when-a-custom', 'lwc-flow-integration', 10),
    ('you-need-to-trigger-a-flow-from-lwc-only-after-multiple-asyn', 'lwc-flow-integration', 10),
    ('how-would-you-handle-governor-limits-and-dml-constraints-if', 'lwc-flow-integration', 10),
    ('how-would-you-initiate-a-stripe-payment-from-an-lwc-componen', 'payment-integrations', 10),
    ('how-do-you-handle-stripe-webhooks-in-a-salesforce-integrated', 'payment-integrations', 10),
    ('can-you-walk-through-a-use-case-where-a-user-purchases-a-pro', 'payment-integrations', 10),
    ('how-would-you-track-payment-success-or-failure-in-salesforce', 'payment-integrations', 10),
    ('what-security-measures-should-be-taken-when-handling-stripe', 'payment-integrations', 10),
    ('what-role-do-wire-adapters-play-in-the-provider-pattern-arch', 'lwc-wire-service', 10),
    ('how-can-you-decouple-business-logic-from-ui-in-a-factory-pro', 'apex-fundamentals', 10),
    ('in-a-factory-pattern-how-do-you-maintain-state-consistency-a', 'apex-fundamentals', 10),
    ('what-are-the-limitations-of-using-wire-in-a-factory-generate', 'lwc-wire-service', 10),
    ('describe-a-mechanism-to-dynamically-bind-different-wire-adap', 'lwc-wire-service', 10),
    ('how-can-you-leverage-browser-storage-like-sessionstorage-or', 'lwc-fundamentals', 10),
    ('how-does-wire-caching-differ-from-imperative-call-caching', 'lwc-wire-service', 10),
    ('can-you-use-sessionstorage-or-localstorage-for-lwc-caching', 'lwc-fundamentals', 10),
    ('how-would-you-implement-a-hybrid-cache-combining-in-memory-s', 'lwc-fundamentals', 10),
    ('how-can-platform-events-or-cdc-help-manage-stale-cache-in-lw', 'platform-events-and-cdc', 10),
    ('how-would-you-securely-handle-docusign-oauth-tokens-in-a-sal', 'docusign-integrations', 10),
    ('how-would-you-track-the-status-of-a-docusign-envelope-and-en', 'docusign-integrations', 10),
    ('if-multiple-recipients-must-sign-in-a-defined-order-how-woul', 'docusign-integrations', 10),
    ('how-would-you-handle-errors-returned-from-the-docusign-api-e', 'docusign-integrations', 10),
    ('how-do-you-securely-send-data-from-your-lwc-to-an-iframe-on', 'lwc-component-communication', 10),
    ('if-messages-sent-from-your-lwc-to-a-partner-iframe-are-silen', 'lwc-component-communication', 10),
    ('how-can-an-lwc-embedded-in-a-visualforce-page-different-doma', 'lwc-component-communication', 10),
    ('what-security-measures-would-you-enforce-to-prevent-cross-si', 'lwc-component-communication', 10),
    ('how-would-you-communicate-between-an-lwc-and-a-third-party-p', 'lwc-component-communication', 10),
    ('how-can-you-fix-the-issue-if-named-credentials-not-refreshin', 'oauth-and-named-credentials', 10),
    ('how-can-you-debug-if-external-system-returns-401-unauthorize', 'oauth-and-named-credentials', 10),
    ('governor-limits-breached-mid-transaction-what-might-be-the-r', 'governor-limits', 10),
    ('apex-callouts-using-named-credentials-throw-invalid-session', 'oauth-and-named-credentials', 10),
    ('why-might-a-named-credential-with-refresh-token-flow-fail-af', 'oauth-and-named-credentials', 10),
    ('lwc-sets-boolean-property-but-it-reads-as-undefined-why', 'lwc-fundamentals', 10),
    ('the-child-emits-event-with-bubbling-composed-but-parent-does', 'apex-fundamentals', 10),
    ('there-is-a-scenario-where-customevent-is-dispatched-but-even', 'apex-fundamentals', 10),
    ('even-lms-message-is-published-but-subscriber-gets-undefined', 'apex-fundamentals', 10),
    ('custom-event-payload-arrives-as-object-object-what-is-the-is', 'lwc-component-communication', 10),
    ('custom-setting-values-are-returning-null-inconsistently-what', 'apex-fundamentals', 10),
    ('apex-logic-is-skipping-expected-validation-rule-errors-why-t', 'flow-automation-patterns', 10),
    ('apex-run-time-varies-drastically-for-the-same-data-volume-wh', 'apex-fundamentals', 10),
    ('you-re-hitting-too-many-callouts-100-error-what-s-the-resolu', 'integration-patterns', 10),
    ('a-soql-query-returns-significantly-more-records-in-productio', 'soql-and-dml-optimization', 10),
    ('i-have-to-delete-300-000-obsolete-records-from-a-custom-obje', 'asynchronous-apex', 10),
    ('what-would-happen-if-you-use-offset-in-soql-for-pagination-b', 'soql-and-dml-optimization', 10),
    ('what-if-you-use-wire-getpicklistvalues-but-forget-to-include', 'lwc-wire-service', 10),
    ('a-nightly-process-inserts-200-000-leads-via-integration-a-be', 'integration-patterns', 10),
    ('what-would-happen-if-you-performed-a-limit-2000-soql-query-a', 'soql-and-dml-optimization', 10),
    ('what-happens-if-you-call-refreshapex-but-don-t-keep-a-refere', 'lwc-wire-service', 10),
    ('what-happens-if-you-put-a-large-console-log-inside-renderedc', 'lwc-rendering-lifecycle', 10),
    ('what-happens-if-your-lwc-component-has-an-infinite-loop-of-p', 'lwc-component-communication', 10),
    ('how-do-you-ensure-an-apex-class-can-run-in-both-synchronous', 'asynchronous-apex', 10),
    ('what-happens-if-you-try-to-send-20-000-emails-in-a-single-tr', 'apex-fundamentals', 10),
    ('what-happens-if-you-call-system-debug-with-a-very-large-stri', 'debugging-and-monitoring', 10),
    ('how-do-you-handle-retries-in-salesforce-when-an-external-sys', 'apex-fundamentals', 10),
    ('how-do-you-secure-outbound-callouts-without-exposing-credent', 'integration-patterns', 10),
    ('how-do-you-enforce-api-rate-limits-in-integrations', 'integration-patterns', 10),
    ('what-happens-if-you-use-json-stringify-on-a-proxy-object-ret', 'lwc-wire-service', 10),
    ('what-happens-if-your-lwc-imports-a-custom-label-that-is-late', 'lwc-fundamentals', 10),
    ('what-happens-if-you-wire-a-method-to-an-apex-class-that-perf', 'lwc-wire-service', 10),
    ('what-happens-if-you-enqueue-a-queueable-job-from-inside-anot', 'asynchronous-apex', 10),
    ('what-happens-if-you-call-schema-describesobjects-for-1-000-o', 'integration-patterns', 10),
    ('how-do-you-handle-bulk-dml-failures-when-one-record-fails-bu', 'apex-fundamentals', 10),
    ('what-happens-if-the-external-api-you-are-calling-sends-a-302', 'integration-patterns', 10),
    ('how-do-you-avoid-callout-timeouts-when-sending-large-payload', 'integration-patterns', 10),
    ('what-happens-if-an-integration-api-returns-mixed-success-and', 'integration-patterns', 10),
    ('what-happens-if-an-api-returns-a-429-too-many-requests-statu', 'integration-patterns', 10),
    ('how-would-you-validate-file-types-and-sizes-before-uploading', 'lwc-fundamentals', 10),
    ('how-would-you-provide-a-file-preview-e-g-pdf-viewer-image-th', 'apex-fundamentals', 10),
    ('how-would-you-handle-large-file-uploads-to-salesforce-ensuri', 'apex-fundamentals', 10),
    ('how-would-you-subscribe-to-and-handle-salesforce-platform-ev', 'platform-events-and-cdc', 10),
    ('how-would-you-ensure-that-multiple-components-consuming-the', 'apex-fundamentals', 10),
    ('how-would-you-handle-scenarios-where-the-user-s-session-disc', 'platform-events-and-cdc', 10),
    ('how-would-you-retrieve-and-display-the-current-approval-stat', 'lwc-fundamentals', 10),
    ('how-would-you-implement-custom-logic-for-approve-reject-acti', 'flow-automation-patterns', 10),
    ('how-would-you-provide-real-time-feedback-to-the-user-after-a', 'flow-automation-patterns', 10),
    ('if-you-dispatch-a-customevent-from-a-child-but-forget-to-set', 'apex-fundamentals', 10),
    ('how-would-you-handle-a-scenario-where-a-parent-passes-a-very', 'lwc-component-communication', 10),
    ('what-happens-if-you-use-for-each-without-specifying-a-unique', 'lwc-rendering-lifecycle', 10),
    ('in-a-future-method-what-happens-if-you-exceed-soql-query-lim', 'asynchronous-apex', 10),
    ('if-two-users-update-the-same-record-at-the-exact-same-time-v', 'apex-fundamentals', 10),
    ('if-you-keep-appending-strings-inside-a-loop-without-using-st', 'governor-limits', 10),
    ('if-salesforce-receives-a-malformed-json-payload-from-an-exte', 'integration-patterns', 10),
    ('if-salesforce-is-making-a-callout-to-a-system-that-takes-2-m', 'integration-patterns', 10),
    ('what-happens-if-an-outbound-message-fails-because-the-extern', 'integration-patterns', 10),
    ('how-do-you-send-large-json-payloads-efficiently-from-salesfo', 'integration-patterns', 10),
    ('what-happens-if-two-components-on-the-same-page-import-the-s', 'crud-fls-sharing', 10),
    ('what-happens-if-you-dispatch-a-custom-event-from-a-child-lwc', 'lwc-component-communication', 10),
    ('how-does-promise-all-behave-in-lwc-if-one-of-the-wired-apex', 'lwc-wire-service', 10),
    ('what-happens-if-you-call-a-future-method-inside-a-batch-fini', 'asynchronous-apex', 10),
    ('how-does-apex-handle-database-saveresult-if-you-perform-an-i', 'soql-and-dml-optimization', 10),
    ('what-happens-if-you-enqueue-a-batchable-job-inside-a-queueab', 'asynchronous-apex', 10),
    ('what-happens-if-a-trigger-throws-an-unhandled-exception-in-a', 'apex-triggers', 10),
    ('what-happens-if-two-triggers-on-the-same-object-update-the-s', 'apex-triggers', 10)
) as seed(question_slug, topic_slug, sort_order)
join public.questions q on q.slug = seed.question_slug
join public.topics t on t.slug = seed.topic_slug
on conflict (question_id, topic_id) do update
set
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

-- question_topics chunk 2
insert into public.question_topics (question_id, topic_id, sort_order)
select q.id, t.id, seed.sort_order
from (
  values
    ('what-happens-if-you-schedule-100-batch-jobs-in-one-transacti', 'asynchronous-apex', 10),
    ('what-happens-if-you-exceed-the-daily-api-request-limit-in-sa', 'governor-limits', 10),
    ('how-can-named-credentials-help-simplify-authentication-in-in', 'integration-patterns', 10),
    ('what-happens-if-an-external-api-you-call-returns-a-500-inter', 'integration-patterns', 10),
    ('how-do-you-manage-partial-failures-when-an-api-sends-100-rec', 'apex-fundamentals', 10),
    ('how-would-you-design-an-lwc-that-can-easily-handle-slow-api', 'lwc-data-and-performance', 10),
    ('how-would-you-design-an-lwc-that-prevents-duplicate-api-call', 'lwc-data-and-performance', 10),
    ('your-lwc-calls-an-api-that-returns-20-000-records-rendering', 'lwc-data-and-performance', 10),
    ('what-happens-if-you-use-track-incorrectly-on-a-non-primitive', 'lwc-fundamentals', 10),
    ('if-a-parent-lwc-uses-api-property-to-pass-data-but-forgets-t', 'lwc-component-communication', 10),
    ('how-does-lwc-handle-multiple-wired-methods-calling-the-same', 'lwc-wire-service', 10),
    ('what-happens-if-you-call-a-queueable-inside-another-queueabl', 'asynchronous-apex', 10),
    ('if-you-use-database-insert-records-false-with-partial-failur', 'soql-and-dml-optimization', 10),
    ('what-happens-if-you-call-system-debug-limits-getqueries-insi', 'governor-limits', 10),
    ('what-happens-if-a-before-trigger-updates-the-same-record-fie', 'apex-triggers', 10),
    ('if-multiple-triggers-exist-on-the-same-object-in-what-order', 'apex-triggers', 10),
    ('what-happens-if-you-call-system-enqueuejob-inside-a-trigger', 'apex-triggers', 10),
    ('what-happens-if-an-http-callout-exceeds-the-120-second-timeo', 'integration-patterns', 10),
    ('if-the-external-system-s-tls-certificate-expires-how-does-sa', 'oauth-and-named-credentials', 10),
    ('how-does-salesforce-handle-large-json-responses-10mb-in-an-h', 'integration-patterns', 10),
    ('your-lwc-fetches-15mb-json-data-from-an-external-api-the-res', 'lwc-data-and-performance', 10),
    ('how-would-you-design-a-search-component-in-lwc-that-avoids-u', 'lwc-fundamentals', 10),
    ('you-have-a-callout-from-apex-that-sometimes-exceeds-the-120', 'integration-patterns', 10),
    ('how-lwc-makes-a-call-to-an-apex-method-that-queries-200k-rec', 'lwc-rendering-lifecycle', 10),
    ('your-lwc-sales-dashboard-crunches-200k-account-and-opportuni', 'lwc-data-and-performance', 10),
    ('your-apex-call-returns-2mb-json-data-that-must-be-sorted-fil', 'apex-fundamentals', 10),
    ('you-need-to-call-an-external-api-that-accepts-only-100-reque', 'integration-patterns', 10),
    ('you-re-building-a-dashboard-lwc-that-aggregates-data-from-5', 'lwc-data-and-performance', 10),
    ('how-would-you-design-an-lwc-that-prevents-multiple-identical', 'lwc-fundamentals', 10),
    ('how-would-you-design-the-apex-callout-to-the-external-api-wh', 'integration-patterns', 10),
    ('how-would-you-handle-failed-validations-or-api-timeouts-grac', 'apex-fundamentals', 10),
    ('how-would-you-secure-api-credentials-and-manage-authenticati', 'apex-fundamentals', 10),
    ('how-would-you-design-this-bidirectional-sync-to-ensure-data', 'apex-fundamentals', 10),
    ('how-would-you-handle-callout-limits-if-multiple-orders-are-c', 'integration-patterns', 10),
    ('how-would-you-design-the-retry-mechanism-for-failed-callouts', 'integration-patterns', 10),
    ('based-on-total-opportunity-revenue-using-only-one-aggregatio', 'soql-and-dml-optimization', 10),
    ('your-query-on-opportunitylineitem-is-running-through-8-milli', 'soql-and-dml-optimization', 10),
    ('you-must-perform-cross-object-filtering-account-case-product', 'soql-and-dml-optimization', 10),
    ('you-re-processing-customer-payments-through-a-rest-api-like', 'payment-integrations', 10),
    ('how-would-you-track-failed-transactions-and-reprocess-them-l', 'apex-fundamentals', 10),
    ('how-would-you-design-an-apex-rest-endpoint-to-receive-and-va', 'apex-fundamentals', 10),
    ('how-would-you-implement-platform-events-or-streaming-api-in', 'platform-events-and-cdc', 10),
    ('how-would-you-design-your-lwc-without-breaking-in-production', 'lwc-fundamentals', 10),
    ('how-would-you-efficiently-share-state-between-multiple-lwcs', 'apex-fundamentals', 10),
    ('how-can-you-validate-a-signed-request-in-apex-to-ensure-the', 'integration-patterns', 10),
    ('what-are-common-causes-of-invalid-signature-errors-during-jw', 'oauth-and-named-credentials', 10),
    ('you-have-to-send-confirmation-emails-to-1m-contacts-after-a', 'apex-fundamentals', 10),
    ('how-do-you-handle-duplicate-webhook-requests-in-apex-to-avoi', 'integration-patterns', 10),
    ('your-apex-rest-api-receives-thousands-of-records-per-request', 'apex-fundamentals', 10),
    ('salesforce-must-send-data-to-an-external-api-that-goes-down', 'integration-patterns', 10),
    ('the-external-api-s-ssl-certificate-rotates-every-3-months-ho', 'oauth-and-named-credentials', 10),
    ('you-need-to-integrate-with-a-third-party-that-only-supports', 'oauth-and-named-credentials', 10),
    ('your-external-service-uses-jwt-based-authentication-how-woul', 'oauth-and-named-credentials', 10),
    ('how-would-you-design-an-lwc-that-cancels-an-ongoing-api-call', 'lwc-fundamentals', 10),
    ('how-would-you-design-an-lwc-that-merges-multiple-api-calls-f', 'lwc-data-and-performance', 10),
    ('what-happens-if-you-use-api-on-a-getter-but-forget-the-corre', 'lwc-fundamentals', 10),
    ('what-failure-occurs-when-an-lwc-tries-to-render-a-list-using', 'lwc-rendering-lifecycle', 10),
    ('what-happens-if-two-child-lwcs-mutate-the-same-reactive-obje', 'apex-fundamentals', 10),
    ('what-happens-if-you-try-json-deserialize-a-payload-that-cont', 'integration-patterns', 10),
    ('what-happens-if-too-many-chained-queueables-cause-the-maximu', 'asynchronous-apex', 10),
    ('if-batch-finish-method-throws-an-unhandled-exception-what-ha', 'asynchronous-apex', 10),
    ('what-happens-if-a-trigger-tries-to-update-a-field-that-has-a', 'apex-triggers', 10),
    ('how-does-salesforce-behave-if-two-triggers-both-re-query-rec', 'soql-and-dml-optimization', 10),
    ('if-a-trigger-calls-a-queueable-that-updates-the-same-object', 'asynchronous-apex', 10),
    ('how-does-salesforce-handle-a-callout-where-the-http-response', 'integration-patterns', 10),
    ('what-happens-if-named-credentials-rotate-their-oauth-token-i', 'oauth-and-named-credentials', 10),
    ('how-does-salesforce-behave-if-the-external-system-returns-a', 'apex-fundamentals', 10),
    ('a-trigger-on-case-uses-callouts-to-an-external-system-in-bul', 'platform-events-and-cdc', 10),
    ('your-apex-returns-a-json-payload-of-1-mb-and-the-browser-tak', 'integration-patterns', 10),
    ('design-an-lwc-that-loads-200-fields-but-renders-only-the-vis', 'lwc-data-and-performance', 10),
    ('an-apex-trigger-calls-an-external-service-to-validate-addres', 'integration-patterns', 10),
    ('the-payment-api-sometimes-completes-the-charge-but-your-apex', 'payment-integrations', 10),
    ('your-apex-callout-times-out-at-120-seconds-but-the-payment-p', 'payment-integrations', 10),
    ('an-lwc-renders-correctly-in-lightning-app-builder-but-fails', 'lwc-flow-integration', 10),
    ('an-lwc-shows-stale-data-after-record-update-even-though-refr', 'lwc-wire-service', 10),
    ('a-child-component-emits-a-customevent-but-the-parent-never-r', 'apex-fundamentals', 10),
    ('an-apex-class-successfully-deserializes-json-but-some-fields', 'integration-patterns', 10),
    ('a-queueable-job-is-enqueued-from-another-queueable-repeatedl', 'asynchronous-apex', 10),
    ('what-happens-if-an-apex-transaction-exceeds-cpu-time-after-d', 'governor-limits', 10),
    ('a-queueable-enqueues-another-queueable-conditionally-why-can', 'asynchronous-apex', 10),
    ('a-trigger-updates-a-record-which-fires-another-trigger-on-th', 'apex-triggers', 10),
    ('a-batch-apex-job-finishes-with-status-completed-but-some-bat', 'asynchronous-apex', 10),
    ('what-happens-if-a-callout-timeout-occurs-after-the-external', 'integration-patterns', 10),
    ('a-callout-succeeds-http-200-but-the-integration-still-fails', 'integration-patterns', 10),
    ('an-external-api-returns-partial-data-with-no-error-code-how', 'integration-patterns', 10),
    ('what-happens-if-refreshapex-is-called-but-the-wired-method-p', 'lwc-wire-service', 10),
    ('how-does-lwc-reactivity-behave-when-a-nested-property-of-a-t', 'lwc-fundamentals', 10),
    ('why-are-callouts-after-dml-restricted-in-synchronous-apex', 'integration-patterns', 10),
    ('is-invoking-a-future-method-from-batch-apex-considered-unsaf', 'asynchronous-apex', 10),
    ('how-is-a-custom-event-handled-if-it-is-dispatched-before-the', 'lwc-component-communication', 10),
    ('why-does-updating-a-field-in-a-before-update-trigger-sometim', 'apex-triggers', 10),
    ('what-happens-if-a-queueable-enqueues-another-queueable-durin', 'asynchronous-apex', 10),
    ('what-happens-if-the-external-api-changes-response-schema-wit', 'integration-patterns', 10),
    ('how-can-trigger-oldmap-contain-values-that-were-never-visibl', 'apex-triggers', 10),
    ('why-do-static-variables-fail-to-prevent-recursion-in-batch-a', 'asynchronous-apex', 10),
    ('why-can-an-apex-getter-return-different-values-in-the-same-t', 'apex-fundamentals', 10),
    ('how-can-trigger-oldmap-contain-values-that-never-existed-in', 'apex-triggers', 10),
    ('why-do-static-variables-reset-between-batch-execute-chunks', 'asynchronous-apex', 10),
    ('why-can-test-stoptest-execute-jobs-in-a-different-order-than', 'asynchronous-apex', 10),
    ('why-does-apex-with-with-sharing-still-expose-records-in-some', 'crud-fls-sharing', 10),
    ('what-breaks-if-the-api-responds-with-http-200-but-returns-a', 'integration-patterns', 10),
    ('why-does-json-deserialization-fail-even-when-field-names-mat', 'apex-fundamentals', 10),
    ('why-might-be-the-reason-that-a-callout-succeed-in-sandbox-bu', 'integration-patterns', 10),
    ('why-do-record-visibility-rules-behave-differently-in-reports', 'crud-fls-sharing', 10),
    ('what-happens-if-a-with-sharing-class-calls-a-without-sharing', 'crud-fls-sharing', 10),
    ('why-can-a-trigger-fire-twice-for-a-single-user-action-withou', 'apex-triggers', 10),
    ('why-does-a-formula-field-value-differ-when-accessed-from-ape', 'flow-automation-patterns', 10),
    ('why-does-without-sharing-not-bypass-object-level-security-in', 'crud-fls-sharing', 10),
    ('c-reports-show-records-that-apex-cannot-access', 'apex-fundamentals', 10),
    ('why-can-duplicate-rules-behave-differently-in-apex-vs-data-l', 'crud-fls-sharing', 10),
    ('what-happens-when-a-with-sharing-class-invokes-a-without-sha', 'crud-fls-sharing', 10),
    ('why-does-mutating-a-nested-property-of-a-track-object-not-tr', 'lwc-fundamentals', 10),
    ('why-does-trigger-old-sometimes-reflect-values-that-were-neve', 'apex-triggers', 10),
    ('why-does-an-api-integration-succeed-when-called-manually-but', 'integration-patterns', 10),
    ('why-does-api-data-arrive-after-connectedcallback', 'lwc-rendering-lifecycle', 10),
    ('what-happens-if-a-customevent-is-dispatched-before-the-paren', 'apex-fundamentals', 10),
    ('what-breaks-if-an-external-api-returns-http-204-with-a-non-e', 'integration-patterns', 10),
    ('why-does-an-lwc-re-render-without-any-tracked-property-chang', 'lwc-rendering-lifecycle', 10),
    ('why-does-test-starttest-reset-limits-but-not-static-memory-i', 'apex-testing', 10),
    ('trigger-oldmap-contains-a-field-value-that-was-never-committ', 'apex-triggers', 10),
    ('why-can-a-batch-apex-finish-method-see-data-that-execute-nev', 'asynchronous-apex', 10),
    ('why-does-trigger-new-sometimes-contain-records-that-fail-val', 'apex-triggers', 10),
    ('what-happens-if-refreshapex-is-called-inside-a-renderedcallb', 'lwc-wire-service', 10),
    ('why-do-named-credentials-work-for-rest-but-fail-for-soap-end', 'apex-fundamentals', 10),
    ('why-does-a-callout-from-a-trigger-work-in-sandbox-but-fail-i', 'integration-patterns', 10),
    ('why-should-dom-access-be-avoided-in-connectedcallback', 'lwc-rendering-lifecycle', 10),
    ('what-happens-if-a-child-fires-an-event-but-the-parent-isn-t', 'apex-fundamentals', 10),
    ('what-happens-if-a-record-is-deleted-while-an-lwc-is-still-wi', 'lwc-wire-service', 10),
    ('why-can-a-soql-query-return-different-results-inside-the-sam', 'soql-and-dml-optimization', 10),
    ('what-happens-if-an-external-api-returns-http-200-but-with-a', 'integration-patterns', 10),
    ('an-lwc-makes-an-imperative-apex-call-triggered-by-user-actio', 'lwc-fundamentals', 10),
    ('salesforce-needs-to-send-a-massive-json-payload-but-heap-siz', 'integration-patterns', 10),
    ('what-happens-if-a-child-dispatches-an-event-before-the-paren', 'apex-fundamentals', 10),
    ('how-is-a-component-affected-when-it-re-renders-inside-a-for', 'lwc-rendering-lifecycle', 10),
    ('how-does-salesforce-handle-callout-responses-that-arrive-aft', 'integration-patterns', 10),
    ('why-can-the-same-soql-query-return-different-results-within', 'soql-and-dml-optimization', 10),
    ('what-happens-if-a-future-method-is-invoked-from-another-asyn', 'asynchronous-apex', 10),
    ('why-why-not-are-callouts-not-allowed-after-partial-dml-opera', 'integration-patterns', 10),
    ('what-happens-if-a-batch-apex-job-is-aborted-while-an-execute', 'asynchronous-apex', 10),
    ('why-does-a-before-insert-trigger-not-have-record-ids-but-aft', 'apex-triggers', 10),
    ('you-have-an-lwc-with-a-tracked-object-if-the-component-reass', 'lwc-fundamentals', 10),
    ('an-external-api-changes-its-response-format-without-notice-h', 'integration-patterns', 10),
    ('what-happens-if-a-trigger-on-a-platform-event-performs-dml', 'platform-events-and-cdc', 10),
    ('what-happens-if-finish-enqueues-another-batch-or-queueable-j', 'asynchronous-apex', 10),
    ('tell-me-about-a-time-you-handled-a-production-issue-under-pr', 'stakeholder-and-behavioral-scenarios', 10),
    ('how-do-you-explain-technical-solutions-to-non-technical-clie', 'stakeholder-and-behavioral-scenarios', 10),
    ('imagine-a-client-has-unrealistic-expectations-on-delivery-ti', 'stakeholder-and-behavioral-scenarios', 10),
    ('describe-a-situation-where-you-worked-with-multiple-teams-ha', 'stakeholder-and-behavioral-scenarios', 10),
    ('what-is-connectedcallback', 'lwc-rendering-lifecycle', 10),
    ('what-are-decorators-in-lwc', 'lwc-rendering-lifecycle', 10)
) as seed(question_slug, topic_slug, sort_order)
join public.questions q on q.slug = seed.question_slug
join public.topics t on t.slug = seed.topic_slug
on conflict (question_id, topic_id) do update
set
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

-- question_topics chunk 3
insert into public.question_topics (question_id, topic_id, sort_order)
select q.id, t.id, seed.sort_order
from (
  values
    ('what-is-the-return-type-of-start-method', 'apex-fundamentals', 10),
    ('but-can-you-debug-why-cpu-time-suddenly-spikes-in-production', 'governor-limits', 10),
    ('or-why-a-seemingly-harmless-flow-brought-the-org-to-its-knee', 'flow-automation-patterns', 10),
    ('how-do-you-design-triggers-and-flows-so-they-don-t-conflict', 'apex-triggers', 10),
    ('a-trigger-works-in-sandbox-but-fails-in-production-how-do-yo', 'debugging-and-monitoring', 10),
    ('what-happens-if-a-future-method-throws-an-exception', 'asynchronous-apex', 10),
    ('your-org-hits-cpu-time-limit-intermittently-how-do-you-ident', 'governor-limits', 10),
    ('what-happens-if-a-governor-limit-is-hit-inside-a-try-block-w', 'governor-limits', 10),
    ('a-deployment-fails-due-to-test-failures-in-unrelated-areas-w', 'apex-testing', 10),
    ('what-s-your-strategy-to-avoid-recursive-triggers-and-automat', 'flow-automation-patterns', 10),
    ('an-external-integration-suddenly-starts-timing-out-how-do-yo', 'integration-patterns', 10),
    ('what-happens-if-an-lwc-throws-an-error-during-the-render-pha', 'lwc-fundamentals', 10),
    ('why-can-two-lwcs-calling-the-same-apex-method-get-different', 'apex-fundamentals', 10),
    ('why-should-integration-logic-avoid-being-placed-directly-ins', 'integration-patterns', 10),
    ('how-can-a-trigger-pass-all-tests-but-still-fail-at-scale-in', 'apex-triggers', 10),
    ('what-happens-if-salesforce-times-out-but-the-external-system', 'apex-fundamentals', 10),
    ('what-happens-if-a-trigger-causes-a-mixed-dml-operation-indir', 'mixed-dml-operations', 10),
    ('can-a-rollback-undo-dml-done-by-a-future-or-queueable-job', 'asynchronous-apex', 10),
    ('what-happens-if-the-api-version-changes-but-salesforce-code', 'apex-fundamentals', 10),
    ('what-happens-when-two-flows-and-a-trigger-update-the-same-fi', 'apex-triggers', 10),
    ('what-happens-if-two-batch-apex-jobs-update-the-same-records', 'asynchronous-apex', 10),
    ('describe-a-situation-where-a-production-issue-was-caused-by', 'stakeholder-and-behavioral-scenarios', 10),
    ('how-do-you-handle-a-teammate-who-repeatedly-breaks-productio', 'stakeholder-and-behavioral-scenarios', 10),
    ('describe-a-situation-where-requirements-changed-mid-sprint-h', 'stakeholder-and-behavioral-scenarios', 10),
    ('what-happens-if-governor-limit-is-hit-inside-a-try-block-wil', 'governor-limits', 10),
    ('how-do-you-handle-callouts-in-batch-or-queueable-safely', 'integration-patterns', 10),
    ('trigger-logic-depends-on-field-change-how-will-you-make-sure', 'apex-triggers', 10),
    ('how-do-you-handle-scenarios-where-multiple-batch-jobs-need-t', 'asynchronous-apex', 10),
    ('if-platform-events-gets-processed-twice-how-would-you-fix-it', 'platform-events-and-cdc', 10),
    ('what-happens-if-the-start-method-returns-a-very-large-queryl', 'asynchronous-apex', 10),
    ('what-does-a-promise-actually-return', 'apex-fundamentals', 10),
    ('why-are-callouts-not-allowed-after-dml-in-the-same-transacti', 'integration-patterns', 10),
    ('what-happens-if-an-lwc-wired-method-returns-data-successfull', 'lwc-wire-service', 10),
    ('why-can-a-trigger-pass-all-tests-but-fail-in-production-at-s', 'apex-triggers', 10),
    ('why-can-two-integrations-updating-the-same-record-at-the-sam', 'integration-patterns', 10),
    ('why-can-batch-apex-process-partial-data-successfully', 'asynchronous-apex', 10),
    ('we-had-a-production-issue-caused-by-a-recent-deployment-what', 'debugging-and-monitoring', 10),
    ('if-there-is-a-team-member-who-is-technically-strong-but-has', 'apex-fundamentals', 10),
    ('if-you-need-to-explain-a-production-failure-to-non-technical', 'stakeholder-and-behavioral-scenarios', 10)
) as seed(question_slug, topic_slug, sort_order)
join public.questions q on q.slug = seed.question_slug
join public.topics t on t.slug = seed.topic_slug
on conflict (question_id, topic_id) do update
set
  sort_order = excluded.sort_order,
  updated_at = timezone('utc', now());

-- PART 5: Answers
-- Answers chunk 1
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'you-have-a-recursive-trigger-on-a-custom-object-and-under-ce',
      'Debugging and Monitoring: Scenario Walkthrough',
      $ans$## Context

You have a recursive trigger on a custom object, and under certain data loads, you're seeing Maximum trigger depth exceeded errors only intermittently. You've already added recursion guards. How do you identify the hidden recursive path and debug it without altering the data model or disabling triggers? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'a-custom-apex-rest-service-starts-throwing-regex-too-complic',
      'Debugging and Monitoring: Scenario Walkthrough',
      $ans$## Context

A custom Apex REST service starts throwing Regex too complicated errors after a recent deployment, but no regex patterns were modified. How would you trace the root cause and debug potential hidden regex compilation issues in large Apex classes? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'an-apex-class-uses-type-forname-and-type-newinstance-for-dyn',
      'Debugging and Monitoring: Scenario Walkthrough',
      $ans$## Context

An Apex class uses Type.forName() and Type.newInstance() for dynamic instantiation. In production, the instantiation randomly fails with System.TypeException: Invalid type. The class exists and compiles. How would you debug this behavior? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-re-debugging-a-too-many-queueable-jobs-added-to-the-queu',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

You're debugging a Too many queueable jobs added to the queue error, but your logic only adds 1 chain per job. There are multiple integrations running in parallel, and the issue doesn't reproduce in sandbox. How would you debug and guard against hidden job fan-outs? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-have-a-method-that-runs-perfectly-in-an-anonymous-window',
      'CRUD, FLS, and Sharing: Scenario Walkthrough',
      $ans$## Context

You have a method that runs perfectly in an anonymous window but fails in a Lightning component with a System.SObjectException: Field is not writeable error on a custom field. The field is accessible via FLS. What hidden cause might be triggering this, and how do you debug it? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-ensure-atomicity-and-rollback-capabilities-when-d',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-implement-a-transactional-idempotent-batch-job',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

How would you implement a transactional, idempotent batch job that integrates with multiple external systems via chained callouts, ensuring rollback, deduplication, and exactly once delivery semantics across batch retries and platform restarts? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-guarantee-data-consistency-and-transactional-inte',
      'Asynchronous Apex: Scenario Walkthrough',
      $ans$## Context

How do you guarantee data consistency and transactional integrity when performing cross object DML operations that span multiple batch execute transactions, especially under partial failures and asynchronous reprocessing scenarios? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-propose-to-process-hierarchical-interdependent',
      'SOQL and DML Optimization: Scenario Walkthrough',
      $ans$## Context

How would you propose to process hierarchical, interdependent records (e.g., Account Opportunity CustomObject__c) across shared data volumes exceeding heap and query limits, and how would you avoid lock contention and race conditions? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-can-you-maintain-referential-integrity-and-avoid-orphane',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-you-tackle-a-governor-limit-resilient-chain-of-queue',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-build-a-platform-native-retry-mesh-that-tracks-jo',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-coordinate-a-multi-pattern-async-convergence-w',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

How would you coordinate a multi pattern async convergence without external schedulers or platform events out of order issues? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-control-job-explosion-enforce-execution-priority',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-enforce-distributed-rollback-coordination-across',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'since-apex-can-t-directly-receive-webhooks-how-can-you-route',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-an-lwc-concurrently-handle-both-platform-events-and',
      'Platform Events and CDC: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Platform Events and CDC logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Platform Events and CDC, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-design-an-lwc-that-processes-cdc-events-for-mi',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

How would you design an LWC that processes CDC events for millions of records without hitting limits? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-can-you-add-retry-logic-in-an-lwc-to-handle-temporary-ap',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-handle-out-of-order-cdc-events-in-lwc-when-multip',
      'Platform Events and CDC: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Platform Events and CDC logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Platform Events and CDC, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'parent-uses-import-c-childcomp-for-lazy-load-child-uses-wire',
      'LWC Component Communication: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'lwc-uses-buildcustomevent-with-bubbling-composition-but-pare',
      'LWC Component Communication: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'lwc-injects-third-party-widget-in-renderedcallback-via-direc',
      'LWC Rendering Lifecycle: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'lwc-uses-lightning-record-edit-form-with-dynamic-recordid-an',
      'LWC Fundamentals: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'in-a-nested-lwc-dashboard-inline-edits-in-one-chart-don-t-re',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

In a nested LWC dashboard, inline edits in one chart don't reflect in others without a full reload. How would you redesign cross component data sync without relying on event flooding? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-built-a-reusable-datatable-with-wire-and-onsave-but-team',
      'LWC Wire Service: Scenario Walkthrough',
      $ans$## Context

You built a reusable datatable with @wire and onSave, but teams report inconsistent inline edit behavior. What design changes ensure clean separation of data, edit lifecycle, and refresh logic for true reusability? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-component-uses-track-for-data-mutations-after-edit-but',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'multiple-lwcs-show-the-same-data-source-after-update-in-one',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'you-re-combining-getrecord-with-imperative-updates-after-sav',
      'Apex Fundamentals: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'when-multiple-lwcs-subscribe-to-the-same-lightning-message-c',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-are-the-implications-of-caching-wire-service-data-in-lw',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-to-manage-component-lifecycle-issues-when-an-lwc-is-dest',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-to-implement-multi-language-support-for-dynamic-field-la',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-to-handle-partial-page-refreshes-in-lwcs-embedded-in-aur',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'you-re-syncing-contacts-across-3-external-systems-via-platfo',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

You're syncing Contacts across 3 external systems via Platform Events. How will you ensure event deduplication and reliable delivery without breaching limits? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'contact-events-are-arriving-before-related-account-data-how',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

Contact events are arriving before related Account data. How do you handle this ordering issue with PushTopics? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-cdc-setup-handles-500k-events-daily-some-events-are-del',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

Your CDC setup handles 500K+ events daily. Some events are delayed or dropped. How do you scale and ensure reliable processing? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'intermittent-timeout-errors-are-impacting-api-reliability-ho',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'given-graphql-is-in-pilot-how-would-you-design-a-performant',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

Given GraphQL is in pilot, how would you design a performant data fetching layer in Salesforce using GraphQL and handle governor limits? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-need-to-sync-5-million-product-records-between-orgs-do-y',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

You need to sync 5 million product records between orgs. Do you use CDC, Bulk API, or both and why? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 2
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'what-are-the-key-lifecycle-events-in-a-websocket-connection',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'can-you-explain-how-lazy-loading-images-or-data-can-affect-a',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-are-the-security-implications-of-exposing-sensitive-dat',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-manage-state-effectively-across-components-in-a-l',
      'LWC Data and Performance: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Data and Performance logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Data and Performance, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-integrate-custom-validation-messages-that-are-bot',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-s-the-best-way-to-secure-the-inbound-slack-interaction',
      'Slack Integrations: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Slack Integrations logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Slack Integrations, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'can-you-open-a-slack-modal-from-a-button-click-in-slack-itse',
      'Slack Integrations: Scenario Walkthrough',
      $ans$## Context

Can you open a Slack modal from a button click in Slack itself, and sync the input back to Salesforce? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-ensure-message-delivery-to-slack-is-reliable-e',
      'Slack Integrations: Scenario Walkthrough',
      $ans$## Context

How would you ensure message delivery to Slack is reliable even if the Salesforce transaction rolls back? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-handle-different-slack-modals-dynamically-base',
      'Slack Integrations: Scenario Walkthrough',
      $ans$## Context

How would you handle different Slack modals dynamically based on the Salesforce object type triggering the event? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-prevent-duplicate-slack-messages-if-the-same-plat',
      'Slack Integrations: Scenario Walkthrough',
      $ans$## Context

How do you prevent duplicate Slack messages if the same platform event is replayed? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'an-lwc-fetches-data-from-3-async-sources-apex-a-platform-eve',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

An LWC fetches data from 3 async sources: Apex, a Platform Event, and a third party API . How will you manage consistent state in the UI ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-re-building-a-secure-lwc-page-that-uses-apex-to-fetch-se',
      'LWC Security and Cross-Domain Messaging: Scenario Walkthrough',
      $ans$## Context

You're building a secure LWC page that uses Apex to fetch sensitive data. The client is worried about exposure. How can you resolve this ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-lwc-makes-a-call-to-apex-but-the-response-takes-3-secon',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

Your LWC makes a call to Apex, but the response takes 3 seconds and blocks UI interaction. How can you fix this ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-need-to-load-different-versions-of-the-same-third-party',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

You need to load different versions of the same third-party library for two components on the same page. How to do it ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-re-combining-lightning-data-service-and-custom-apex-call',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

You're combining Lightning Data Service and custom Apex calls in the same LWC. How to maintain consistency in such case ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'after-launching-a-flow-from-lwc-how-do-you-handle-the-onstat',
      'LWC and Flow Integration: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC and Flow Integration logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC and Flow Integration, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-refresh-lwc-data-after-the-embedded-flow-updates',
      'LWC and Flow Integration: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC and Flow Integration logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC and Flow Integration, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-you-start-an-embedded-flow-in-lwc-only-when-a-custom',
      'LWC and Flow Integration: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC and Flow Integration logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC and Flow Integration, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'you-need-to-trigger-a-flow-from-lwc-only-after-multiple-asyn',
      'LWC and Flow Integration: Scenario Walkthrough',
      $ans$## Context

You need to trigger a Flow from LWC only after multiple async Apex calls complete. How would you do this ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-handle-governor-limits-and-dml-constraints-if',
      'LWC and Flow Integration: Scenario Walkthrough',
      $ans$## Context

How would you handle governor limits and DML constraints if a Flow (launched from LWC) deals with bulk updates? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-initiate-a-stripe-payment-from-an-lwc-componen',
      'Payment Integrations: Scenario Walkthrough',
      $ans$## Context

How would you initiate a Stripe payment from an LWC component? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-handle-stripe-webhooks-in-a-salesforce-integrated',
      'Payment Integrations: Scenario Walkthrough',
      $ans$## Context

How do you handle Stripe webhooks in a Salesforce integrated payment flow? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'can-you-walk-through-a-use-case-where-a-user-purchases-a-pro',
      'Payment Integrations: Scenario Walkthrough',
      $ans$## Context

Can you walk through a use case where a user purchases a product using Stripe via LWC? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-track-payment-success-or-failure-in-salesforce',
      'Payment Integrations: Scenario Walkthrough',
      $ans$## Context

How would you track payment success or failure in Salesforce after Stripe redirects the user? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-security-measures-should-be-taken-when-handling-stripe',
      'Payment Integrations: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Payment Integrations logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Payment Integrations, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-role-do-wire-adapters-play-in-the-provider-pattern-arch',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-you-decouple-business-logic-from-ui-in-a-factory-pro',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'in-a-factory-pattern-how-do-you-maintain-state-consistency-a',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-are-the-limitations-of-using-wire-in-a-factory-generate',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'describe-a-mechanism-to-dynamically-bind-different-wire-adap',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-you-leverage-browser-storage-like-sessionstorage-or',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-wire-caching-differ-from-imperative-call-caching',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'can-you-use-sessionstorage-or-localstorage-for-lwc-caching',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-implement-a-hybrid-cache-combining-in-memory-s',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you implement a hybrid cache combining in-memory, sessionStorage, and LDS in LWC? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-can-platform-events-or-cdc-help-manage-stale-cache-in-lw',
      'Platform Events and CDC: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Platform Events and CDC logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Platform Events and CDC, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-securely-handle-docusign-oauth-tokens-in-a-sal',
      'DocuSign Integrations: Scenario Walkthrough',
      $ans$## Context

How would you securely handle DocuSign OAuth tokens in a Salesforce LWC initiated integration? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-track-the-status-of-a-docusign-envelope-and-en',
      'DocuSign Integrations: Scenario Walkthrough',
      $ans$## Context

How would you track the status of a DocuSign envelope and ensure Salesforce records are updated once the document is signed? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'if-multiple-recipients-must-sign-in-a-defined-order-how-woul',
      'DocuSign Integrations: Scenario Walkthrough',
      $ans$## Context

If multiple recipients must sign in a defined order, how would you design the envelope and route the signing flow through OmniScript and DocuSign? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-handle-errors-returned-from-the-docusign-api-e',
      'DocuSign Integrations: Scenario Walkthrough',
      $ans$## Context

How would you handle errors returned from the DocuSign API (e.g., invalid recipient, template not found) in OmniScript or LWC? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-securely-send-data-from-your-lwc-to-an-iframe-on',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 3
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'if-messages-sent-from-your-lwc-to-a-partner-iframe-are-silen',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-an-lwc-embedded-in-a-visualforce-page-different-doma',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-security-measures-would-you-enforce-to-prevent-cross-si',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-communicate-between-an-lwc-and-a-third-party-p',
      'LWC Component Communication: Scenario Walkthrough',
      $ans$## Context

How would you communicate between an LWC and a third party page inside an iframe? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-can-you-fix-the-issue-if-named-credentials-not-refreshin',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

How can you fix the issue if Named Credentials not refreshing tokens ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-can-you-debug-if-external-system-returns-401-unauthorize',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

How can you debug if External system returns 401 Unauthorized to Salesforce callout even with correct Named Credential ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'governor-limits-breached-mid-transaction-what-might-be-the-r',
      'Governor Limits: Scenario Walkthrough',
      $ans$## Context

Governor limits breached mid transaction , What might be the Root cause ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'apex-callouts-using-named-credentials-throw-invalid-session',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

Apex callouts using Named Credentials throw INVALID_SESSION_ID how would you resolve? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'why-might-a-named-credential-with-refresh-token-flow-fail-af',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

Why might a Named Credential with refresh token flow fail after 90 days with Google APIs? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'lwc-sets-boolean-property-but-it-reads-as-undefined-why',
      'LWC Fundamentals: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'the-child-emits-event-with-bubbling-composed-but-parent-does',
      'Apex Fundamentals: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'there-is-a-scenario-where-customevent-is-dispatched-but-even',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

There is a scenario where CustomEvent is dispatched, but event.target is null , how can you fix it ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'even-lms-message-is-published-but-subscriber-gets-undefined',
      'Apex Fundamentals: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'custom-event-payload-arrives-as-object-object-what-is-the-is',
      'LWC Component Communication: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'custom-setting-values-are-returning-null-inconsistently-what',
      'Apex Fundamentals: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'apex-logic-is-skipping-expected-validation-rule-errors-why-t',
      'Flow Automation Patterns: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'apex-run-time-varies-drastically-for-the-same-data-volume-wh',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

Apex run time varies drastically for the same data volume. What's causing the fluctuation ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-re-hitting-too-many-callouts-100-error-what-s-the-resolu',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

You're hitting Too many callouts: 100 error. What's the resolution? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'a-soql-query-returns-significantly-more-records-in-productio',
      'SOQL and DML Optimization: Scenario Walkthrough',
      $ans$## Context

A SOQL query returns significantly more records in production than sandbox . What's the Fix ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'i-have-to-delete-300-000-obsolete-records-from-a-custom-obje',
      'Asynchronous Apex: Scenario Walkthrough',
      $ans$## Context

I have to delete 300,000 obsolete records from a custom object. I don't want to use Batch Apex, and I can't use Bulk API because of org policy. How do I do this using regular Apex code?\" - Air Asia asked this to one of my student? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-would-happen-if-you-use-offset-in-soql-for-pagination-b',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-if-you-use-wire-getpicklistvalues-but-forget-to-include',
      'LWC Wire Service: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'a-nightly-process-inserts-200-000-leads-via-integration-a-be',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

A nightly process inserts 200,000 leads via integration. A before insert trigger enriches them with Account data, but the integration often fails with \"Too many SOQL queries.\" How do you make the enrichment bulk-safe without dropping the logic? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-would-happen-if-you-performed-a-limit-2000-soql-query-a',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-call-refreshapex-but-don-t-keep-a-refere',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-put-a-large-console-log-inside-renderedc',
      'LWC Rendering Lifecycle: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'what-happens-if-your-lwc-component-has-an-infinite-loop-of-p',
      'LWC Component Communication: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'how-do-you-ensure-an-apex-class-can-run-in-both-synchronous',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-try-to-send-20-000-emails-in-a-single-tr',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-call-system-debug-with-a-very-large-stri',
      'Debugging and Monitoring: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Debugging and Monitoring logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Debugging and Monitoring, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-handle-retries-in-salesforce-when-an-external-sys',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-secure-outbound-callouts-without-exposing-credent',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-enforce-api-rate-limits-in-integrations',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-use-json-stringify-on-a-proxy-object-ret',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-your-lwc-imports-a-custom-label-that-is-late',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-wire-a-method-to-an-apex-class-that-perf',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-enqueue-a-queueable-job-from-inside-anot',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-call-schema-describesobjects-for-1-000-o',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-handle-bulk-dml-failures-when-one-record-fails-bu',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-the-external-api-you-are-calling-sends-a-302',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 4
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'how-do-you-avoid-callout-timeouts-when-sending-large-payload',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-an-integration-api-returns-mixed-success-and',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-an-api-returns-a-429-too-many-requests-statu',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-validate-file-types-and-sizes-before-uploading',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you validate file types and sizes before uploading in LWC? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-provide-a-file-preview-e-g-pdf-viewer-image-th',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you provide a file preview (e.g., PDF viewer, image thumbnail) to the user? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-handle-large-file-uploads-to-salesforce-ensuri',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you handle large file uploads to Salesforce, ensuring performance and reliability? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-subscribe-to-and-handle-salesforce-platform-ev',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

How would you subscribe to and handle Salesforce Platform Events in LWC? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-ensure-that-multiple-components-consuming-the',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you ensure that multiple components consuming the same event remain in sync? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-handle-scenarios-where-the-user-s-session-disc',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

How would you handle scenarios where the user's session disconnects from the event stream? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-retrieve-and-display-the-current-approval-stat',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you retrieve and display the current approval status and pending approvers in LWC? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-implement-custom-logic-for-approve-reject-acti',
      'Flow Automation Patterns: Scenario Walkthrough',
      $ans$## Context

How would you implement custom logic for approve/reject actions while still respecting Salesforce approval rules? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-provide-real-time-feedback-to-the-user-after-a',
      'Flow Automation Patterns: Scenario Walkthrough',
      $ans$## Context

How would you provide real time feedback to the user after an approval/rejection action (e.g., toast, UI refresh)? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'if-you-dispatch-a-customevent-from-a-child-but-forget-to-set',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-handle-a-scenario-where-a-parent-passes-a-very',
      'LWC Component Communication: Scenario Walkthrough',
      $ans$## Context

How would you handle a scenario where a parent passes a very large JSON object to a child LWC multiple times? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-you-use-for-each-without-specifying-a-unique',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'in-a-future-method-what-happens-if-you-exceed-soql-query-lim',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-two-users-update-the-same-record-at-the-exact-same-time-v',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-you-keep-appending-strings-inside-a-loop-without-using-st',
      'Governor Limits: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Governor Limits logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Governor Limits, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-salesforce-receives-a-malformed-json-payload-from-an-exte',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-salesforce-is-making-a-callout-to-a-system-that-takes-2-m',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-an-outbound-message-fails-because-the-extern',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-send-large-json-payloads-efficiently-from-salesfo',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

How do you send large JSON payloads efficiently from Salesforce to an external API ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-two-components-on-the-same-page-import-the-s',
      'CRUD, FLS, and Sharing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing CRUD, FLS, and Sharing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For CRUD, FLS, and Sharing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-dispatch-a-custom-event-from-a-child-lwc',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-promise-all-behave-in-lwc-if-one-of-the-wired-apex',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-call-a-future-method-inside-a-batch-fini',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-apex-handle-database-saveresult-if-you-perform-an-i',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-enqueue-a-batchable-job-inside-a-queueab',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-trigger-throws-an-unhandled-exception-in-a',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-two-triggers-on-the-same-object-update-the-s',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-schedule-100-batch-jobs-in-one-transacti',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-exceed-the-daily-api-request-limit-in-sa',
      'Governor Limits: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Governor Limits logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Governor Limits, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-named-credentials-help-simplify-authentication-in-in',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-an-external-api-you-call-returns-a-500-inter',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-manage-partial-failures-when-an-api-sends-100-rec',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How do you manage partial failures when an API sends 100 records to Salesforce but only 90 succeed? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-an-lwc-that-can-easily-handle-slow-api',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

How would you design an LWC that can easily handle slow API responses (e.g., showing spinners, async retries, or fallback data)? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-an-lwc-that-prevents-duplicate-api-call',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

How would you design an LWC that prevents duplicate API calls when a user clicks a button multiple times quickly? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-lwc-calls-an-api-that-returns-20-000-records-rendering',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

Your LWC calls an API that returns 20,000 records. Rendering them directly freezes the browser. How would you handle this scenario? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-you-use-track-incorrectly-on-a-non-primitive',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-a-parent-lwc-uses-api-property-to-pass-data-but-forgets-t',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 5
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'how-does-lwc-handle-multiple-wired-methods-calling-the-same',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-call-a-queueable-inside-another-queueabl',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-you-use-database-insert-records-false-with-partial-failur',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-call-system-debug-limits-getqueries-insi',
      'Governor Limits: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Governor Limits logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Governor Limits, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-before-trigger-updates-the-same-record-fie',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-multiple-triggers-exist-on-the-same-object-in-what-order',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-call-system-enqueuejob-inside-a-trigger',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-an-http-callout-exceeds-the-120-second-timeo',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-the-external-system-s-tls-certificate-expires-how-does-sa',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

If the external system's TLS certificate expires, how does Salesforce integration behave? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-does-salesforce-handle-large-json-responses-10mb-in-an-h',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'your-lwc-fetches-15mb-json-data-from-an-external-api-the-res',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

Your LWC fetches 15MB JSON data from an external API. The response takes 10+ seconds and sometimes times out. How would you optimize both backend and frontend handling? - Recently Asked in KPMG? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-a-search-component-in-lwc-that-avoids-u',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you design a search component in LWC that avoids unnecessary server calls while the user is typing? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-have-a-callout-from-apex-that-sometimes-exceeds-the-120',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

You have a callout from Apex that sometimes exceeds the 120 second timeout due to slow external API response. How would you design a reliable, retry safe solution? - Recently asked in EY? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-lwc-makes-a-call-to-an-apex-method-that-queries-200k-rec',
      'LWC Rendering Lifecycle: Scenario Walkthrough',
      $ans$## Context

How LWC makes a call to an Apex method that queries 200k records. The UI freezes for (8-10 seconds) before rendering. How would you design both Apex and LWC to improve performance? - Recently Asked in an Interview? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-lwc-sales-dashboard-crunches-200k-account-and-opportuni',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

Your LWC sales dashboard crunches 200k+ Account and Opportunity records but executives face (8-10 second) UI freezes and tab crashes on load. The dashboard needs to display aggregated insights, top performers, and drill downs all with a smooth, responsive experience. How would you fix it? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-apex-call-returns-2mb-json-data-that-must-be-sorted-fil',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

Your Apex call returns 2MB JSON data that must be sorted, filtered, and grouped before rendering. How would you design the Apex component ? - Recently Asked in an Interview? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-need-to-call-an-external-api-that-accepts-only-100-reque',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

You need to call an external API that accepts only 100 requests per minute, but your org may trigger thousands. How do you throttle or batch these calls efficiently? - An Interview Question That Caught My Attention Recently? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-re-building-a-dashboard-lwc-that-aggregates-data-from-5',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

You're building a dashboard LWC that aggregates data from 5 different objects. How would you structure Apex and caching to improve performance? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-an-lwc-that-prevents-multiple-identical',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you design an LWC that prevents multiple identical API calls made within a short time window even if triggered from different components? - A Common Interview Scenario That Confuses Many Devs? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-the-apex-callout-to-the-external-api-wh',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

How would you design the Apex callout to the external API while ensuring the transaction is not delayed or blocked? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-handle-failed-validations-or-api-timeouts-grac',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you handle failed validations or API timeouts gracefully in the UI ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-secure-api-credentials-and-manage-authenticati',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-would-you-design-this-bidirectional-sync-to-ensure-data',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you design this bidirectional sync to ensure data consistency and avoid duplicates? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-handle-callout-limits-if-multiple-orders-are-c',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

How would you handle callout limits if multiple orders are created simultaneously? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-the-retry-mechanism-for-failed-callouts',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

How would you design the retry mechanism for failed callouts or ERP unavailability? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'based-on-total-opportunity-revenue-using-only-one-aggregatio',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'your-query-on-opportunitylineitem-is-running-through-8-milli',
      'SOQL and DML Optimization: Scenario Walkthrough',
      $ans$## Context

Your query on OpportunityLineItem is running through 8 million records , how would you improve its performance using custom indexes? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-must-perform-cross-object-filtering-account-case-product',
      'SOQL and DML Optimization: Scenario Walkthrough',
      $ans$## Context

You must perform cross object filtering (Account Case Product__c) in one SOQL like query . How will you do it in Apex ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-re-processing-customer-payments-through-a-rest-api-like',
      'Payment Integrations: Scenario Walkthrough',
      $ans$## Context

You're processing customer payments through a REST API (like Stripe or Razorpay). How do you ensure that if the payment succeeds externally but fails to update in Salesforce, you don't double charge the user? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-track-failed-transactions-and-reprocess-them-l',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you track failed transactions and reprocess them later without duplicating successful ones? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-an-apex-rest-endpoint-to-receive-and-va',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you design an Apex REST endpoint to receive and validate these securely ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-implement-platform-events-or-streaming-api-in',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

How would you implement Platform Events or Streaming API in LWC to keep data in sync? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-your-lwc-without-breaking-in-production',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you design your LWC without breaking in production? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-efficiently-share-state-between-multiple-lwcs',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-you-validate-a-signed-request-in-apex-to-ensure-the',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-are-common-causes-of-invalid-signature-errors-during-jw',
      'OAuth and Named Credentials: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing OAuth and Named Credentials logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For OAuth and Named Credentials, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'you-have-to-send-confirmation-emails-to-1m-contacts-after-a',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

You have to send confirmation emails to 1M Contacts after a data migration , how would you design this without hitting limits? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-handle-duplicate-webhook-requests-in-apex-to-avoi',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

How do you handle duplicate webhook requests in Apex to avoid processing the same request twice ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-apex-rest-api-receives-thousands-of-records-per-request',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

Your Apex REST API receives thousands of records per request , how do you handle partial failures and ensure no data loss? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'salesforce-must-send-data-to-an-external-api-that-goes-down',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

Salesforce must send data to an external API that goes down intermittently , how would you ensure delivery once it's back online? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 6
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'the-external-api-s-ssl-certificate-rotates-every-3-months-ho',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

The external API's SSL certificate rotates every 3 months , how do you handle this automatically in Salesforce? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'you-need-to-integrate-with-a-third-party-that-only-supports',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

You need to integrate with a third party that only supports OAuth 2.0 authorization code flow , how can Salesforce authenticate without manual user consent? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-external-service-uses-jwt-based-authentication-how-woul',
      'OAuth and Named Credentials: Scenario Walkthrough',
      $ans$## Context

Your external service uses JWT based authentication , how would you generate and refresh tokens securely from Apex? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-an-lwc-that-cancels-an-ongoing-api-call',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

How would you design an LWC that cancels an ongoing API call if the user changes a filter before the first response arrives? - A tricky interview question? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-would-you-design-an-lwc-that-merges-multiple-api-calls-f',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

How would you design an LWC that merges multiple API calls from different components into one batched Apex callout? - The One Interview Topic You Can't Afford to Miss? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-you-use-api-on-a-getter-but-forget-the-corre',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-failure-occurs-when-an-lwc-tries-to-render-a-list-using',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-two-child-lwcs-mutate-the-same-reactive-obje',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-you-try-json-deserialize-a-payload-that-cont',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-too-many-chained-queueables-cause-the-maximu',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-batch-finish-method-throws-an-unhandled-exception-what-ha',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-trigger-tries-to-update-a-field-that-has-a',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-salesforce-behave-if-two-triggers-both-re-query-rec',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'if-a-trigger-calls-a-queueable-that-updates-the-same-object',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-salesforce-handle-a-callout-where-the-http-response',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-named-credentials-rotate-their-oauth-token-i',
      'OAuth and Named Credentials: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing OAuth and Named Credentials logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For OAuth and Named Credentials, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-salesforce-behave-if-the-external-system-returns-a',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'a-trigger-on-case-uses-callouts-to-an-external-system-in-bul',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

A trigger on Case uses callouts to an external system. In bulk operations (100 records), callouts fail. You cannot move logic to a Flow or Platform Event. How do you solve this? - Air Asia asked this in a Recent Technical Round? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-apex-returns-a-json-payload-of-1-mb-and-the-browser-tak',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

Your Apex returns a JSON payload of 1 MB and the browser takes 3-5 seconds to parse it. How do you restructure the response to minimize parsing overhead? - The One Technical Concept You Must Know Before Your Interview? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'design-an-lwc-that-loads-200-fields-but-renders-only-the-vis',
      'LWC Data and Performance: Scenario Walkthrough',
      $ans$## Context

Design an LWC that loads 200+ fields but renders only the visible viewport fields (virtual scrolling) to avoid lag? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'an-apex-trigger-calls-an-external-service-to-validate-addres',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

An Apex trigger calls an external service to validate addresses. In a bulk update of 200 records, only 10% validation is needed. The rest are duplicates or unchanged. How do you reduce callout volume using Apex patterns? - A Crucial concept IBM asked last Week to filter good candidates? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'the-payment-api-sometimes-completes-the-charge-but-your-apex',
      'Payment Integrations: Scenario Walkthrough',
      $ans$## Context

The Payment API sometimes completes the charge, but your Apex callout hits a timeout. How do you make sure so the user is never double charged? - Recently asked in a Visa Sponsored Technical round? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'your-apex-callout-times-out-at-120-seconds-but-the-payment-p',
      'Payment Integrations: Scenario Walkthrough',
      $ans$## Context

Your Apex callout times out at 120 seconds, but the payment provider still completes the charge. A retry would double charge the customer. How do you design the integration so the payment is processed only once even if the response is lost? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'an-lwc-renders-correctly-in-lightning-app-builder-but-fails',
      'LWC and Flow Integration: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'an-lwc-shows-stale-data-after-record-update-even-though-refr',
      'LWC Wire Service: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'a-child-component-emits-a-customevent-but-the-parent-never-r',
      'Apex Fundamentals: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'an-apex-class-successfully-deserializes-json-but-some-fields',
      'Integration Resilience Patterns: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'a-queueable-job-is-enqueued-from-another-queueable-repeatedl',
      'Asynchronous Apex: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'what-happens-if-an-apex-transaction-exceeds-cpu-time-after-d',
      'Governor Limits: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Governor Limits logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Governor Limits, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'a-queueable-enqueues-another-queueable-conditionally-why-can',
      'Asynchronous Apex: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'a-trigger-updates-a-record-which-fires-another-trigger-on-th',
      'Apex Triggers: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'a-batch-apex-job-finishes-with-status-completed-but-some-bat',
      'Asynchronous Apex: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'what-happens-if-a-callout-timeout-occurs-after-the-external',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'a-callout-succeeds-http-200-but-the-integration-still-fails',
      'Integration Resilience Patterns: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'an-external-api-returns-partial-data-with-no-error-code-how',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

An external API returns partial data with no error code. How should Apex defensively handle this scenario? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-refreshapex-is-called-but-the-wired-method-p',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-lwc-reactivity-behave-when-a-nested-property-of-a-t',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-are-callouts-after-dml-restricted-in-synchronous-apex',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'is-invoking-a-future-method-from-batch-apex-considered-unsaf',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-is-a-custom-event-handled-if-it-is-dispatched-before-the',
      'LWC Component Communication: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Component Communication logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Component Communication, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 7
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'why-does-updating-a-field-in-a-before-update-trigger-sometim',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-queueable-enqueues-another-queueable-durin',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-the-external-api-changes-response-schema-wit',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-trigger-oldmap-contain-values-that-were-never-visibl',
      'Apex Triggers: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'why-do-static-variables-fail-to-prevent-recursion-in-batch-a',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-an-apex-getter-return-different-values-in-the-same-t',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-trigger-oldmap-contain-values-that-never-existed-in',
      'Apex Triggers: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'why-do-static-variables-reset-between-batch-execute-chunks',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-test-stoptest-execute-jobs-in-a-different-order-than',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-apex-with-with-sharing-still-expose-records-in-some',
      'CRUD, FLS, and Sharing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing CRUD, FLS, and Sharing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For CRUD, FLS, and Sharing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-breaks-if-the-api-responds-with-http-200-but-returns-a',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-json-deserialization-fail-even-when-field-names-mat',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-might-be-the-reason-that-a-callout-succeed-in-sandbox-bu',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

Why might be the reason that a callout succeed in sandbox but fail in production? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'why-do-record-visibility-rules-behave-differently-in-reports',
      'CRUD, FLS, and Sharing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing CRUD, FLS, and Sharing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For CRUD, FLS, and Sharing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-with-sharing-class-calls-a-without-sharing',
      'CRUD, FLS, and Sharing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing CRUD, FLS, and Sharing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For CRUD, FLS, and Sharing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-a-trigger-fire-twice-for-a-single-user-action-withou',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-a-formula-field-value-differ-when-accessed-from-ape',
      'Flow Automation Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Flow Automation Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Flow Automation Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-without-sharing-not-bypass-object-level-security-in',
      'CRUD, FLS, and Sharing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing CRUD, FLS, and Sharing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For CRUD, FLS, and Sharing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'c-reports-show-records-that-apex-cannot-access',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-duplicate-rules-behave-differently-in-apex-vs-data-l',
      'CRUD, FLS, and Sharing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing CRUD, FLS, and Sharing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For CRUD, FLS, and Sharing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-when-a-with-sharing-class-invokes-a-without-sha',
      'CRUD, FLS, and Sharing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing CRUD, FLS, and Sharing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For CRUD, FLS, and Sharing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-mutating-a-nested-property-of-a-track-object-not-tr',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-trigger-old-sometimes-reflect-values-that-were-neve',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-an-api-integration-succeed-when-called-manually-but',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

Why does an API integration succeed when called manually but fail when invoked from a trigger? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'why-does-api-data-arrive-after-connectedcallback',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-customevent-is-dispatched-before-the-paren',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-breaks-if-an-external-api-returns-http-204-with-a-non-e',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-an-lwc-re-render-without-any-tracked-property-chang',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-test-starttest-reset-limits-but-not-static-memory-i',
      'Apex Testing: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Testing logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Testing, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'trigger-oldmap-contains-a-field-value-that-was-never-committ',
      'Apex Triggers: Code Review Analysis',
      $ans$## Code

```apex
trigger AccountTrigger on Account (after insert, after update) {
    for (Account a : Trigger.new) {
        List<Contact> contacts = [
            SELECT Id, LastName
            FROM Contact
            WHERE AccountId = :a.Id
        ];

        for (Contact c : contacts) {
            c.LastName = c.LastName + ' Updated';
            update c;
        }
    }
}
```

Brief context: this trigger tries to update related Contacts whenever Accounts are inserted or updated.

## Issue: SOQL and DML in Nested Loops

**Line(s):** 3-13  
**Severity:** Critical  
**Category:** Governor Limit

The trigger queries Contacts per Account and updates each Contact individually. In bulk operations this quickly exceeds SOQL and DML limits.

```apex
Map<Id, List<Contact>> contactsByAccount = new Map<Id, List<Contact>>();
List<Contact> updates = new List<Contact>();
```

## Issue: Missing Recursion Guard and Change Filter

**Line(s):** 1-13  
**Severity:** Warning  
**Category:** Logic Error

The trigger runs for every update without checking if relevant fields changed, and there is no recursion guard. This can cause repeated updates and unstable behavior.

```apex
if (!Trigger.isAfter || !Trigger.isUpdate) return;
// Add field-change checks before applying updates.
```

## Corrected Version

```apex
trigger AccountTrigger on Account (after update) {
    Set<Id> accountIds = new Set<Id>();
    for (Account a : Trigger.new) {
        Account oldRec = Trigger.oldMap.get(a.Id);
        if (a.Name != oldRec.Name) { // process only meaningful change
            accountIds.add(a.Id);
        }
    }

    if (accountIds.isEmpty()) return;

    List<Contact> updates = new List<Contact>();
    for (Contact c : [
        SELECT Id, LastName
        FROM Contact
        WHERE AccountId IN :accountIds
    ]) {
        c.LastName = c.LastName + ' Updated';
        updates.add(c);
    }

    if (!updates.isEmpty()) {
        update updates; // one DML statement
    }
}
```

> [!CAUTION]
> The original version can fail bulk data operations and block deployments because it performs SOQL and DML inside loops.

## Review Summary

| # | Issue | Severity | Category |
| --- | --- | --- | --- |
| 1 | SOQL and DML in nested loops | Critical | Governor Limit |
| 2 | Missing change filter and recursion control | Warning | Logic Error |

> [!TIP]
> In code-review interviews, explain intended behavior first, then walk through limits, bulkification, and failure risk in order of impact.$ans$
    ),
    (
      'why-can-a-batch-apex-finish-method-see-data-that-execute-nev',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-trigger-new-sometimes-contain-records-that-fail-val',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-refreshapex-is-called-inside-a-renderedcallb',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-do-named-credentials-work-for-rest-but-fail-for-soap-end',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-a-callout-from-a-trigger-work-in-sandbox-but-fail-i',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

Why does a callout from a trigger work in sandbox but fail in production? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'why-should-dom-access-be-avoided-in-connectedcallback',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-child-fires-an-event-but-the-parent-isn-t',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-record-is-deleted-while-an-lwc-is-still-wi',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-a-soql-query-return-different-results-inside-the-sam',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-an-external-api-returns-http-200-but-with-a',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 8
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'an-lwc-makes-an-imperative-apex-call-triggered-by-user-actio',
      'LWC Fundamentals: Scenario Walkthrough',
      $ans$## Context

An LWC makes an imperative Apex call triggered by user actions. Users double click rapidly and duplicate requests hit the server. How would you design the component to prevent this without blocking the UI? - Recently asked in a Visa Sponsored round? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'salesforce-needs-to-send-a-massive-json-payload-but-heap-siz',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

Salesforce needs to send a massive JSON payload, but heap size and callout limits are screaming. How would you solve this? - Recently asked in an Interview? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-a-child-dispatches-an-event-before-the-paren',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-is-a-component-affected-when-it-re-renders-inside-a-for',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-does-salesforce-handle-callout-responses-that-arrive-aft',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-the-same-soql-query-return-different-results-within',
      'SOQL and DML Optimization: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing SOQL and DML Optimization logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For SOQL and DML Optimization, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-future-method-is-invoked-from-another-asyn',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-why-not-are-callouts-not-allowed-after-partial-dml-opera',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-a-batch-apex-job-is-aborted-while-an-execute',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-does-a-before-insert-trigger-not-have-record-ids-but-aft',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'you-have-an-lwc-with-a-tracked-object-if-the-component-reass',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'an-external-api-changes-its-response-format-without-notice-h',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

An external API changes its response format without notice. How should your callout handling adapt? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-a-trigger-on-a-platform-event-performs-dml',
      'Platform Events and CDC: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Platform Events and CDC logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Platform Events and CDC, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-finish-enqueues-another-batch-or-queueable-j',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'tell-me-about-a-time-you-handled-a-production-issue-under-pr',
      'Stakeholder and Behavioral Scenarios: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Stakeholder and Behavioral Scenarios logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Stakeholder and Behavioral Scenarios, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-explain-technical-solutions-to-non-technical-clie',
      'Stakeholder and Behavioral Scenarios: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Stakeholder and Behavioral Scenarios logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Stakeholder and Behavioral Scenarios, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'imagine-a-client-has-unrealistic-expectations-on-delivery-ti',
      'Stakeholder and Behavioral Scenarios: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Stakeholder and Behavioral Scenarios logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Stakeholder and Behavioral Scenarios, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'describe-a-situation-where-you-worked-with-multiple-teams-ha',
      'Stakeholder and Behavioral Scenarios: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Stakeholder and Behavioral Scenarios logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Stakeholder and Behavioral Scenarios, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-is-connectedcallback',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-are-decorators-in-lwc',
      'LWC Rendering Lifecycle: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Rendering Lifecycle logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Rendering Lifecycle, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-is-the-return-type-of-start-method',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'but-can-you-debug-why-cpu-time-suddenly-spikes-in-production',
      'Governor Limits: Scenario Walkthrough',
      $ans$## Context

But can you debug why CPU time suddenly spikes in production after a release? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'or-why-a-seemingly-harmless-flow-brought-the-org-to-its-knee',
      'Flow Automation Patterns: Scenario Walkthrough',
      $ans$## Context

Or why a seemingly harmless Flow brought the org to its knees? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-design-triggers-and-flows-so-they-don-t-conflict',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'a-trigger-works-in-sandbox-but-fails-in-production-how-do-yo',
      'Debugging and Monitoring: Scenario Walkthrough',
      $ans$## Context

A trigger works in sandbox but fails in production. How do you debug it? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-a-future-method-throws-an-exception',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'your-org-hits-cpu-time-limit-intermittently-how-do-you-ident',
      'Governor Limits: Scenario Walkthrough',
      $ans$## Context

Your org hits CPU time limit intermittently. How do you identify the root cause? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-a-governor-limit-is-hit-inside-a-try-block-w',
      'Governor Limits: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Governor Limits logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Governor Limits, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'a-deployment-fails-due-to-test-failures-in-unrelated-areas-w',
      'Apex Testing: Scenario Walkthrough',
      $ans$## Context

A deployment fails due to test failures in unrelated areas. What do you do? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-s-your-strategy-to-avoid-recursive-triggers-and-automat',
      'Flow Automation Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Flow Automation Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Flow Automation Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'an-external-integration-suddenly-starts-timing-out-how-do-yo',
      'Integration Resilience Patterns: Scenario Walkthrough',
      $ans$## Context

An external integration suddenly starts timing out. How do you troubleshoot it? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-an-lwc-throws-an-error-during-the-render-pha',
      'LWC Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-two-lwcs-calling-the-same-apex-method-get-different',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-should-integration-logic-avoid-being-placed-directly-ins',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-can-a-trigger-pass-all-tests-but-still-fail-at-scale-in',
      'Apex Triggers: Scenario Walkthrough',
      $ans$## Context

How can a trigger pass all tests but still fail at scale in production? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-salesforce-times-out-but-the-external-system',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

What happens if Salesforce times out but the external system completes the operation? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-a-trigger-causes-a-mixed-dml-operation-indir',
      'Mixed DML Operations: Scenario Walkthrough',
      $ans$## Context

What happens if a trigger causes a mixed DML operation indirectly? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'can-a-rollback-undo-dml-done-by-a-future-or-queueable-job',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-the-api-version-changes-but-salesforce-code',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

What happens if the API version changes but Salesforce code is not updated? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-when-two-flows-and-a-trigger-update-the-same-fi',
      'Apex Triggers: Scenario Walkthrough',
      $ans$## Context

What happens when two flows and a trigger update the same field differently? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

-- Answers chunk 9
insert into public.answers (question_id, title, content_markdown, is_primary, status, published_at)
select q.id, seed.title, seed.content_markdown, true, 'published'::public.content_status, timezone('utc', now())
from (
  values
    (
      'what-happens-if-two-batch-apex-jobs-update-the-same-records',
      'Asynchronous Apex: Scenario Walkthrough',
      $ans$## Context

What happens if two Batch Apex jobs update the same records concurrently? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'describe-a-situation-where-a-production-issue-was-caused-by',
      'Stakeholder and Behavioral Scenarios: Scenario Walkthrough',
      $ans$## Context

Describe a situation where a production issue was caused by your own change. How did you handle accountability? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'how-do-you-handle-a-teammate-who-repeatedly-breaks-productio',
      'Stakeholder and Behavioral Scenarios: Scenario Walkthrough',
      $ans$## Context

How do you handle a teammate who repeatedly breaks production but is technically strong? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'describe-a-situation-where-requirements-changed-mid-sprint-h',
      'Stakeholder and Behavioral Scenarios: Scenario Walkthrough',
      $ans$## Context

Describe a situation where requirements changed mid sprint. How did you adapt without derailing delivery? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-governor-limit-is-hit-inside-a-try-block-wil',
      'Governor Limits: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Governor Limits logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Governor Limits, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-handle-callouts-in-batch-or-queueable-safely',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'trigger-logic-depends-on-field-change-how-will-you-make-sure',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'how-do-you-handle-scenarios-where-multiple-batch-jobs-need-t',
      'Asynchronous Apex: Scenario Walkthrough',
      $ans$## Context

How do you handle scenarios where multiple batch jobs need to run in sequence? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'if-platform-events-gets-processed-twice-how-would-you-fix-it',
      'Platform Events and CDC: Scenario Walkthrough',
      $ans$## Context

If Platform events gets processed twice , how would you fix it to prevent duplicates ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'what-happens-if-the-start-method-returns-a-very-large-queryl',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-does-a-promise-actually-return',
      'Apex Fundamentals: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Fundamentals logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Fundamentals, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-are-callouts-not-allowed-after-dml-in-the-same-transacti',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'what-happens-if-an-lwc-wired-method-returns-data-successfull',
      'LWC Wire Service: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing LWC Wire Service logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For LWC Wire Service, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-a-trigger-pass-all-tests-but-fail-in-production-at-s',
      'Apex Triggers: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Apex Triggers logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Apex Triggers, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-two-integrations-updating-the-same-record-at-the-sam',
      'Integration Resilience Patterns: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Integration Resilience Patterns logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Integration Resilience Patterns, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'why-can-batch-apex-process-partial-data-successfully',
      'Asynchronous Apex: Interview Answer',
      $ans$## Key Points

- Define transaction boundaries and failure points before implementing Asynchronous Apex logic.
- Keep processing bulk-safe and idempotent so retries do not create duplicate side effects.
- Use selective queries and controlled DML to stay inside governor limits.
- Add observability so production failures can be diagnosed quickly.

## Detailed Explanation

This question checks whether you can move from concept to execution under real Salesforce constraints. A strong response explains which operations run synchronously, which should move to asynchronous processing, and how you protect data consistency when partial failures occur.

For Asynchronous Apex, interviewers also expect tradeoff awareness. You should compare at least one alternative, explain governor-limit implications, and describe how your approach behaves at scale. Mention transaction scope, record locking, and retry behavior where relevant.

In production, correctness is not enough. You also need maintainability. Use clear separation between orchestration and helper logic, include explicit error handling, and emit enough context in logs to support incident triage.

## Example

```apex
public with sharing class InterviewPrepExample {
    public static void execute(List<Account> scope) {
        if (scope == null || scope.isEmpty()) return;

        List<Account> updates = new List<Account>();
        for (Account record : scope) {
            if (String.isBlank(record.Description)) {
                record.Description = 'Processed safely';
                updates.add(record);
            }
        }

        if (!updates.isEmpty()) {
            update updates;
        }
    }
}
```

The example keeps logic collection-based and performs one DML statement, which is safer under bulk load.

## Best Practices

- Keep SOQL and DML outside loops.
- Use idempotency keys for external side effects.
- Record correlation IDs to trace failures across systems.
- Write tests for both happy path and partial-failure behavior.

> [!TIP]
> In interviews, explain not only what works, but also how the design fails safely under retries and high data volume.

## Common Mistakes

- Solving for one record and ignoring bulk execution.
- Missing retry protection, which causes duplicate writes.
- Ignoring lock contention and transaction ordering.
- Returning vague answers without concrete production safeguards.$ans$
    ),
    (
      'we-had-a-production-issue-caused-by-a-recent-deployment-what',
      'Debugging and Monitoring: Scenario Walkthrough',
      $ans$## Context

We had a production issue caused by a recent deployment. What steps will you take to identify the root cause and stabilize the system? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'if-there-is-a-team-member-who-is-technically-strong-but-has',
      'Apex Fundamentals: Scenario Walkthrough',
      $ans$## Context

If there is a team member who is technically strong but has caused instability in production. How did you handle this situation? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    ),
    (
      'if-you-need-to-explain-a-production-failure-to-non-technical',
      'Stakeholder and Behavioral Scenarios: Scenario Walkthrough',
      $ans$## Context

If you need to explain a production failure to non technical stakeholders. What would be your next steps ? is a production design scenario where correctness, scale, and recovery behavior all matter. The key is to keep business operations reliable even when external dependencies fail or platform limits are reached.

Success criteria should include deterministic processing, idempotent retries, and clear operational visibility. You should also define how failures are surfaced, retried, and reconciled without data drift.

## Approach: Synchronous Validation with Async Recovery

Use synchronous checks only for fast validation and record acceptance, then persist a durable work item for downstream processing. Execute heavy work in Queueable or Batch where limits are higher and retry logic is explicit.

```apex
if (isValid(payload)) {
    insert new Integration_Work_Item__c(Status__c = 'Queued');
    System.enqueueJob(new ProcessWorkItemJob());
}
```

This approach keeps user transactions responsive while preserving recoverability.

## Approach: Event-Driven Orchestration with Replay-Safe Consumers

Publish a platform event that carries a stable idempotency key. Consumers process events asynchronously, store processing state, and ignore duplicates based on the key.

```apex
Event_Bus__e evt = new Event_Bus__e(Idempotency_Key__c = requestKey);
Database.SaveResult sr = EventBus.publish(evt);
```

This approach decouples producers and consumers and scales better across teams, but adds operational complexity.

## Tradeoffs

| Criteria | Synchronous Validation with Async Recovery | Event-Driven Orchestration with Replay-Safe Consumers |
| --- | --- | --- |
| Scalability | Medium | High |
| Maintainability | High | Medium |
| Cost | Medium | Medium |
| Time to Implement | Fast | Slower |
| Governor Limit Risk | Medium | Lower |
| Failure Isolation | Medium | High |
| Cross-Team Extensibility | Medium | High |

## Recommendation

Start with synchronous validation plus async recovery when delivery speed matters and integration fan-out is limited. Move to event-driven orchestration when multiple consumers, replay handling, or long-term extensibility becomes a requirement.

A hybrid model is often best: validate quickly in the request path, then emit events for downstream side effects and analytics.

> [!TIP]
> State assumptions early, compare two viable approaches, and justify your recommendation with failure-handling details.

## Follow-ups

- "How would you prevent duplicate processing?"  
  Use a durable idempotency key and an upsert-based processing ledger.
- "How would you monitor failures?"  
  Track queue depth, retry counts, and dead-letter conditions with alert thresholds.
- "What if volume doubles in one month?"  
  Increase async worker parallelism and partition processing by key range.
- "How would you handle partial downstream outages?"  
  Isolate failing endpoints, apply exponential backoff, and continue non-dependent work.$ans$
    )
) as seed(question_slug, title, content_markdown)
join public.questions q on q.slug = seed.question_slug
on conflict do nothing;

commit;
